title,link,publish_date,content
"Yiannis Antoniou, Lab49: OpenAI Operator kickstarts era of browser AI agents",https://www.artificialintelligence-news.com/news/yiannis-antoniou-lab49-openai-operator-era-browser-ai-agents/,2025-01-24 14:03:14+00:00,"Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry), Bluesky (@gadgetry.bsky.social), and/or Mastodon (@gadgetry@techhub.social)

OpenAI has unveiled Operator, a tool that integrates seamlessly with web browsers to perform tasks autonomously. From filling out forms to ordering groceries, Operator promises to simplify repetitive online activities by interacting directly with websites through clicks, typing, and scrolling.

Designed around a new model called the Computer-Using Agent (CUA), Operator combines GPT-4o’s vision recognition with advanced reasoning capabilities—allowing it to function as a virtual “human-in-the-browser.” Yet, for all its innovation, industry experts see room for refinement.

Yiannis Antoniou, Head of AI, Data, and Analytics at specialist consultancy Lab49, shared his insights on Operator’s significance and positioning in the competitive landscape of agent AI systems.

Agentic AI through a familiar interface

“OpenAI’s announcement of Operator, its latest foray into the agentic AI wars, is both fascinating and incomplete,” said Antoniou, who has over two decades of experience designing AI systems for financial services firms.

“Clearly influenced by Anthropic Claude’s Computer Use system, introduced back in October, Operator streamlines the experience by removing the need for complex infrastructure and focusing on a familiar interface: the browser.”

By designing Operator to operate within an environment users already understand, the web browser, OpenAI sidesteps the need for bespoke APIs or integrations.

“By leveraging the world’s most popular interface, OpenAI enhances the user experience and captures immediate interest from the general public. This browser-centric approach creates significant potential for widespread adoption, something Anthropic – despite its early-mover advantage – has struggled to achieve.”

Unlike some competing systems that may feel technical or niche in their application, Operator’s browser-focused framework lowers the barrier to entry and is a step forward in OpenAI’s efforts to democratise AI.

Unique take on usability and security

One of the hallmarks of Operator is its emphasis on adaptability and security, implemented through human-in-the-loop protocols. Antoniou acknowledged these thoughtful usability features but noted that more work is needed.

“Architecturally, Operator’s browser integration closely mirrors Claude’s system. Both involve taking screenshots of the user’s browser and sending them for analysis, as well as controlling the screen via virtual keystrokes and mouse movements. However, Operator introduces thoughtful usability touches.

“Features like custom instructions for specific websites add a layer of personalisation, and the emphasis on human-in-the-loop safeguards against unauthorised actions – such as purchases, sending emails, or applying for jobs – demonstrate OpenAI’s awareness of potential security risks posed by malicious websites, but more work is clearly needed to make this system widely safe across a variety of scenarios.”

OpenAI has implemented a multi-layered safety framework for Operator, including takeover mode for secure inputs, user confirmations prior to significant actions, and monitoring systems to detect adversarial behavior. Furthermore, users can delete browsing data and manage privacy settings directly within the tool.

However, Antoniou emphasised that these measures are still evolving—particularly as Operator encounters complex or sensitive tasks.

OpenAI Operator further democratises AI

Antoniou also sees the release of Operator as a pivotal moment for the consumer AI landscape, albeit one that is still in its early stages.

“Overall, this is an excellent first attempt at building an agentic system for everyday users, designed around how they naturally interact with technology. As the system develops – with added capabilities and more robust security controls – this limited rollout, priced at $200/month, will serve as a testing ground.

“Once matured and extended to lower subscription tiers and the free version, Operator has the potential to usher in the era of consumer-facing agents, further democratising AI and embedding it into daily life.”

Designed initially for Pro users at a premium price point, Operator provides OpenAI with an opportunity to learn from early adopters and refine its capabilities.

Antoniou noted that while $200/month might not yet justify the system’s value for most users, investment in making Operator more powerful and accessible could lead to significant competitive advantages for OpenAI in the long run.

“Is it worth $200/month? Perhaps not yet. But as the system evolves, OpenAI’s moat will grow, making it harder for competitors to catch up. Now, the challenge shifts back to Anthropic and Google – both of whom have demonstrated similar capabilities in niche or engineering-focused products – to respond and stay in the game,” he concludes.

As OpenAI continues to fine-tune Operator, the potential to revolutionise how people interact with technology becomes apparent. From collaborations with companies like Instacart, DoorDash, and Uber to use cases in the public sector, Operator aims to balance innovation with trust and safety.

While early limitations and pricing may deter widespread adoption for now, these hurdles might only be temporary as OpenAI commits to enhancing usability and accessibility over time.

See also: OpenAI argues against ChatGPT data deletion in Indian court

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
How AI helped refine Hungarian accents in The Brutalist,https://www.artificialintelligence-news.com/news/how-ai-helped-refine-hungarian-accents-in-the-brutalist/,2025-01-24 13:38:07+00:00,"As a tech journalist, Zul focuses on topics including cloud computing, cybersecurity, and disruptive technology in the enterprise industry. He has expertise in moderating webinars and presenting content on video, in addition to having a background in networking technology.

When it comes to movies buzzing with Oscar potential, Brady Corbet’s The Brutalist is a standout this awards season.

The visually stunning drama transports viewers to the post-World War II era, unravelling the story of László Tóth, played by Adrien Brody. Tóth, a fictional Hungarian-Jewish architect, starts over in the United States after being forced to leave his family behind as he emigrates.

Beyond its vintage allure, something modern brews in the background: the use of AI. Specifically, AI was employed to refine Brody’s and co-star Felicity Jones’ Hungarian pronunciation. The decision has sparked lively debates about technology’s role in film-making.

The role of AI in The Brutalist

According to Dávid Jancsó, the film’s editor, the production team turned to Respeecher, an AI software developed by a Ukrainian company, to tweak the actors’ Hungarian dialogue. Speaking to RedShark News (as cited by Mashable SEA), Jancsó explained that Hungarian – a Uralic language known for its challenging sounds – was a significant hurdle for the actors, despite their talent and dedication.

Respeecher’s software isn’t magic, but just a few years ago, it would have seemed wondrous. It creates a voice model based on a speaker’s characteristics and adjusts specific elements, like pronunciation. In this case, it was used to fine-tune the letter and vowel sounds that Brody and Jones found tricky. Most of the corrections were minimal, with Jancsó himself providing some replacement sounds to preserve the authenticity of the performances. “Most of their Hungarian dialogue has a part of me talking in there,” he joked, emphasising the care taken to maintain the actors’ original delivery.

Respeecher: AI behind the scenes

The is not Respeecher’s first foray into Hollywood. The software is known for restoring iconic voices like that of Darth Vader for the Obi-Wan Kenobi series, and has recreated Edith Piaf’s voice for an upcoming biopic. Outside of film, Respeecher has helped to preserve endangered languages like Crimean Tatar.

For The Brutalist, the AI tool wasn’t just a luxury – it was a time and budget saver. With so much dialogue in Hungarian, manually editing every line would have required painstaking, manual work. Jancsó said that using AI sped up the process significantly, an important factor given the film’s modest $10 million budget.

Beyond voice: AI’s other roles in the film

AI was also used in other aspects of the production process, used for example to generate some of Tóth’s architectural drawings and complete buildings in the film’s Venice Biennale sequence. However, director Corbet has clarified that these images were not fully AI-generated; instead, the AI was used for specific background elements.

Corbet and Jancsó have been candid about their perspectives on AI in film-making. Jancsó sees it as a valuable tool, saying, “There’s nothing in the film using AI that hasn’t been done before. It just makes the process a lot faster.” Corbet added that the software’s purpose was to enhance authenticity, not replace the actors’ hard work.

A broader conversation

The debate surrounding AI in the film industry isn’t new. From script-writing to music production, concerns about generative AI’s impact were central to the 2023 Writers Guild of America (WGA) and SAG-AFTRA strikes. Although agreements have been reached to regulate the use of AI, the topic remains a hot-button issue.

The Brutalist awaits a possible Oscar nomination. From its story line to its cinematic style, the film wears its ambition on its sleeve. It’s not just a celebration of the postwar Brutalist architectural movement, it’s also a nod to classic American cinema. Shot in the rarely used VistaVision format, the film captures the grandeur of mid-20th-century film-making. Adding to its nostalgic charm, it includes a 15-minute intermission during its epic three-and-a-half-hour runtime.

Yet the use of AI has given a new dimension to the ongoing conversation about AI in the creative industry. Whether people see AI as a betrayal of craftsmanship or an exciting innovative tool that can add to a final creation, one thing is certain: AI continues to transform how stories are delivered on screen.

See also: AI music sparks new copyright battle in US courts

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
OpenAI targets business sector with advanced AI tools,https://www.artificialintelligence-news.com/news/openai-targets-business-sector-advanced-ai-tools/,2025-01-24 13:30:53+00:00,"OpenAI, the powerhouse behind ChatGPT, is ramping up efforts to dominate the enterprise market with a suite of AI tools tailored for business users.

The company recently revealed its plans to introduce a series of enhancements designed to make AI integration seamless for companies of all sizes. This includes updates to its flagship AI agent technology, expected to transform workplace productivity by automating complex workflows, from financial analysis to customer service.

“Businesses are looking for solutions that go beyond surface-level assistance. Our agents are designed to provide in-depth, actionable insights,” said Sarah Friar, CFO of OpenAI. “This is particularly relevant as enterprises seek to streamline operations in today’s competitive landscape.”

OpenAI’s corporate strategy builds on its ongoing collaborations with tech leaders such as Microsoft, which has already integrated OpenAI’s technology into its Azure cloud platform. Analysts say these partnerships position OpenAI to rival established enterprise solutions providers like Salesforce and Oracle.

AI research assistant tools

As part of its enterprise-focused initiatives, OpenAI is emphasising the development of AI research tools that cater to specific industries.

For instance, its AI models are being trained on legal and medical data to create highly specialised assistants that could redefine research-intensive sectors. This focus aligns with the broader market demand for AI-driven solutions that enhance decision-making and efficiency.

Infrastructure for expansion

OpenAI’s rapid growth strategy is supported by a robust infrastructure push. The company has committed to building state-of-the-art data centers in Europe and Asia, aiming to lower latency and improve service reliability for global users. These investments reflect OpenAI’s long-term vision of becoming a critical enabler in the AI-driven global economy.

Challenges and issues

However, challenges persist. The company faces mounting pressure from regulators concerned about data privacy and the ethical implications of deploying powerful AI tools. Critics also question the sustainability of OpenAI’s ambitious growth targets, given its significant operational costs and strong competition from other tech giants.

Despite these hurdles, OpenAI remains optimistic about its trajectory. With plans to unveil its expanded portfolio at the upcoming Global AI Summit, the company is well-positioned to strengthen its foothold in the burgeoning AI enterprise market.

(Editor’s note: This article is sponsored by AI Tools Network)

See also: OpenAI argues against ChatGPT data deletion in Indian court

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
OpenAI argues against ChatGPT data deletion in Indian court,https://www.artificialintelligence-news.com/news/openai-argues-against-chatgpt-data-deletion-in-indian-court/,2025-01-23 14:24:49+00:00,"As a tech journalist, Zul focuses on topics including cloud computing, cybersecurity, and disruptive technology in the enterprise industry. He has expertise in moderating webinars and presenting content on video, in addition to having a background in networking technology.

OpenAI has argued in an Indian court that removing the training data behind ChatGPT service would clash with its legal obligations in the United States.

The statement was issued in response to a lawsuit filed by Indian news agency ANI, which accused the AI business of using its content without permission.

The Microsoft-backed AI giant stated that Indian courts lack jurisdiction in the case since OpenAI has no offices nor operations in the country. In its January 10 filing to the Delhi High Court, OpenAI emphasised that it is already defending similar lawsuits in the US, where it is required to preserve its training data during ongoing litigation.

The case, filed by ANI in November, is one of India’s most closely-watched lawsuits involving the use of AI. ANI alleges that OpenAI utilised its published content without authorisation to train ChatGPT and is demanding the deletion of its data from the company’s systems.

A global battle over copyright and AI

OpenAI is no stranger to such disputes, facing a wave of lawsuits from copyright holders worldwide. In the US, the New York Times filed a similar case against the company, accusing it of misusing its content. OpenAI has consistently denied such allegations, claiming its systems rely on the fair use of publicly available data.

During a November hearing in Delhi, OpenAI told the court it would no longer use ANI’s content. However, ANI argued that its previously published material remains stored in ChatGPT’s repositories and must be deleted.

In its rebuttal, OpenAI highlighted that it is legally obligated under US law to retain training data while related cases are pending. “The company is under a legal obligation, under the laws of the United States, to preserve, and not delete, the said training data,” OpenAI stated in its filing.

Jurisdiction dispute

OpenAI also argued that the relief ANI is seeking falls outside the jurisdiction of Indian courts. It pointed out that the company has “no office or permanent establishment in India,” and its servers, which store ChatGPT’s training data, are located outside the country.

ANI, which is partially owned by Reuters, countered the claim, saying the Delhi court has the authority to hear the case and that it will file a detailed response.

A Reuters spokesperson declined to comment on proceedings, but has stated that the agency has no involvement in ANI’s business operations.

Concerns over competition

ANI has also expressed concern about unfair competition, citing OpenAI’s partnerships with major news organisations like Time Magazine, The Financial Times, and France’s Le Monde. ANI says that these agreements give OpenAI an edge.

The agency further claimed that ChatGPT reproduces verbatim or similar excerpts of its works in response to user prompts. OpenAI, on the other hand, claimed that ANI deliberately used its own articles as prompts to “manipulate ChatGPT” to file the lawsuit.

The case is scheduled to be heard by the Delhi High Court on January 28. Meanwhile, OpenAI is transitioning from a non-profit to a for-profit company, raising $6.6 billion last year.

In recent months, OpenAI has secured high-profile deals with media outlets from around the world, highlighting its efforts to strengthen its commercial partnerships while managing regulatory concerns worldwide.

(Photo by Unsplash)

See also: DeepSeek-R1 reasoning models rival OpenAI in performance

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
World Economic Forum unveils blueprint for equitable AI,https://www.artificialintelligence-news.com/news/world-economic-forum-unveils-blueprint-equitable-ai/,2025-01-21 16:55:43+00:00,"Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry), Bluesky (@gadgetry.bsky.social), and/or Mastodon (@gadgetry@techhub.social)

The World Economic Forum (WEF) has released a blueprint outlining how AI can drive inclusivity in global economic growth and societal progress. However, it also highlights the challenges in ensuring its benefits are equitably distributed across all nations and peoples.

Developed in partnership with KPMG, the blueprint offers nine strategic objectives to support government leaders, organisations, and key stakeholders through every phase of the AI lifecycle – from innovation to deployment – at local, national, and international levels. These strategies aim to bridge disparities in AI access, infrastructure, advanced computing, and skill development to promote sustainable, long-term growth.

Cathy Li, Head of AI, Data, and the Metaverse at the WEF, said: “Leveraging AI for economic growth and societal progress is a shared goal, yet countries and regions have very different starting points.

“This blueprint serves as a compass, guiding decision-makers toward impact-oriented collaboration and practical solutions that can unlock AI’s full potential.”

Call for regional collaboration and local empowerment

Central to the ‘Blueprint for Intelligent Economies’ is the belief that successful AI adoption must reflect the specific needs of local communities—with strong leadership and collaboration among governments, businesses, entrepreneurs, civil society organisations, and end users.

Solly Malatsi, South Africa’s Minister of Communications and Digital Technologies, commented: “The significant potential of AI remains largely untapped in many regions worldwide. Establishing an inclusive and competitive AI ecosystem will become a crucial priority for all nations.

“Collaboration among multiple stakeholders at the national, regional, and global levels will be essential in fostering growth and prosperity through AI for everyone.”

By tailoring approaches to reflect geographic and cultural nuances, the WEF report suggests nations can create AI systems that address local challenges while also providing a robust bedrock for innovation, investment, and ethical governance. Case studies from nations at varying stages of AI maturity are used throughout the report to illustrate practical, scalable solutions.

For example, cross-border cooperation on shared AI frameworks and pooled resources (such as energy or centralised databanks) is highlighted as a way to overcome resource constraints. Public-private subsidies to make AI-ready devices more affordable present another equitable way forward. These mechanisms aim to lower barriers for local businesses and innovators, enabling them to adopt AI tools and scale their operations.

Hatem Dowidar, Chief Executive Officer of E&, said: “All nations have a unique opportunity to advance their economic and societal progress through AI. This requires a collaborative approach of intentional leadership from governments supported by active engagement with all stakeholders at all stages of the AI journey.

“Regional and global collaborations remain fundamental pathways to address shared challenges and opportunities, ensure equitable access to key AI capabilities, and responsibly maximise its transformative potential for a lasting value for all.”

Priority focus areas

While the blueprint features nine strategic objectives, three have been singled out as priority focus areas for national AI strategies:

Building sustainable AI infrastructure

Resilient, scalable, and environmentally sustainable AI infrastructure is essential for innovation. However, achieving this vision will require substantial investment, energy, and cross-sector collaboration. Nations must coordinate efforts to ensure that intelligent economies grow in both an equitable and eco-friendly manner.

Curating diverse and high-quality datasets

AI’s potential hinges on the quality of the data it can access. This strategic objective addresses barriers such as data accessibility, imbalance, and ownership. By ensuring that datasets are inclusive, diverse, and reflective of local languages and cultures, developers can create equitable AI models that avoid bias and meet the needs of all communities.

Establishing robust ethical and safety guardrails

Governance frameworks are critical for reducing risks like misuse, bias, and ethical breaches. By setting high standards at the outset, nations can cultivate trust in AI systems, laying the groundwork for responsible deployment and innovation. These safeguards are especially vital for promoting human-centred AI that benefits all of society.

The overall framework outlined in the report has three layers:

Foundation layer: Focuses on sustainable energy, diverse data curation, responsible AI infrastructure, and efficient investment mechanisms. Growth layer: Embeds AI into workflows, processes, and devices to accelerate sectoral adoption and boost innovation. People layer: Prioritises workforce skills, empowerment, and ethical considerations, ensuring that AI shapes society in a beneficial and inclusive way.

A blueprint for global AI adoption

The Forum is also championing a multi-stakeholder approach to global AI adoption, blending public and private collaboration. Policymakers are being encouraged to implement supportive legislation and incentives to spark innovation and broaden AI’s reach. Examples include lifelong learning programmes to prepare workers for the AI-powered future and financial policies that enable greater technology access in underserved regions.

The WEF’s latest initiative reflects growing global recognition that AI will be a cornerstone of the future economy. However, it remains clear that the benefits of this transformative technology will need to be shared equitably to drive societal progress and ensure no one is left behind.

The Blueprint for Intelligent Economies provides a roadmap for nations to harness AI while addressing the structural barriers that could otherwise deepen existing inequalities. By fostering inclusivity, adopting robust governance, and placing communities at the heart of decision-making, the WEF aims to guide governments, businesses, and innovators toward a sustainable and intelligent future.

See also: UK Government signs off sweeping AI action plan

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
Galileo launches Agentic Evaluations to fix AI agent errors before they cost you,https://venturebeat.com/ai/galileo-launches-agentic-evaluations-to-fix-ai-agent-errors-before-they-cost-you/,2025-01-23 13:00:00+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

Galileo, a San Francisco-based startup, is betting that the future of artificial intelligence depends on trust. Today, the company launched a new product, Agentic Evaluations, to address a growing challenge in the world of AI: making sure the increasingly complex systems known as AI agents actually work as intended.

AI agents — autonomous systems that perform multi-step tasks like generating reports or analyzing customer data — are gaining traction across industries. But their rapid adoption raises a crucial question: How can companies verify these systems remain reliable after deployment? Galileo’s CEO, Vikram Chatterji, believes his company has found the answer.

“Over the last six to eight months, we started to see some of our customers trying to adopt agentic systems,” said Chatterji in an interview. “Now LLMs can be used as a smart router to pick and choose the right API calls towards actually completing a task. Going from just generating text to actually completing a task was a very big chasm that was unlocked.”

A diagram showing how Galileo evaluates AI agents at three key stages: tool selection, error detection and task completion. (Credit: Galileo)

AI agents show promise, but enterprises demand accountability

Major enterprises like Cisco and Ema (the latter founded by Coinbase’s former chief product officer) have already adopted Galileo’s platform. These companies use AI agents to automate tasks from customer support to financial analysis, and report significant productivity gains.

“A sales representative who’s trying to do outreach and outbounds would otherwise use maybe a week of their time to do that, versus with some of these AI-enabled agents, they’re doing that within two days or less,” Chatterji explained, highlighting the return on investment for enterprises.

Galileo’s new framework evaluates tool selection quality, detects errors in tool calls, and tracks overall session success. It also monitors essential metrics for large-scale AI deployment, including costs and latency.

A dashboard showing how Galileo evaluates AI agents at three key stages: tool selection, error detection and task completion. (Credit: Galileo)

$68 million in funding fuels Galileo’s push into enterprise AI

The launch builds on Galileo’s recent momentum. The company raised $45 million in series B funding led by Scale Venture Partners last October, bringing its total funding to $68 million. Industry analysts project the market for AI operations tools could reach $4 billion by 2025.

The stakes are high as AI deployment accelerates. Studies show even advanced models like GPT-4 can hallucinate about 23% of the time during basic question-and-answer tasks. Galileo’s tools help enterprises identify these issues before they impact operations.

“Before we launch this thing, we really, really need to know that this thing works,” Chatterji said, describing customer concerns. “The bar is really high. So that’s where we gave them this tool chain, such that they could just use our metrics as the basis for these tests.”

Addressing AI hallucinations and enterprise-scale challenges

The company’s focus on reliable, production-ready solutions positions it well in a market increasingly concerned with AI safety. For technical leaders deploying enterprise AI, Galileo’s platform provides essential guardrails for ensuring AI agents perform as intended while controlling costs.

As enterprises expand their use of AI agents, performance monitoring tools become crucial infrastructure. Galileo’s latest offering aims to help businesses deploy AI responsibly and effectively at scale.

“2025 will be the year of agents. It is going to be very prolific,” Chatterji noted. “However, what we’ve also seen is a lot of companies that are just launching these agents without good testing is leading to negative implications…The need for proper testing and evaluations is more than ever before.”"
"Perplexity launches Sonar API, taking aim at Google and OpenAI with real-time AI search",https://venturebeat.com/ai/perplexity-launches-sonar-api-taking-aim-at-google-and-openai-with-real-time-ai-search/,2025-01-21 22:31:58+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

Perplexity has launched an aggressive bid to capture the enterprise AI search market, unveiling Sonar, an API service that outperforms offerings from Google, OpenAI and Anthropic on key benchmarks while also undercutting their prices.

The move signals a significant shift in the AI landscape, as Perplexity — now valued at $9 billion — directly challenges larger competitors by making its real-time, web-connected search capabilities available to developers and enterprises.

The company’s dual-tier strategy — offering both a lightweight Sonar service and a more robust Sonar Pro version — targets different segments of the growing AI integration market.

Perplexity’s Sonar Pro outperforms major AI competitors in the SimpleQA benchmark, which measures response accuracy. (Credit: Perplexity)



Sonar’s real-time advantage: Bringing fresh data to enterprises

Zoom has already integrated Sonar into its AI Companion 2.0 product, allowing users to access real-time information without leaving video conferences — a capability that could reshape how businesses conduct remote meetings and research.

The pricing structure appears to be designed to disrupt the market. Sonar’s base tier costs $5 per 1,000 searches plus minimal token fees, while Sonar Pro, despite higher token costs, offers doubled citation density and multi-search capabilities for complex queries.

What sets Sonar apart is its real-time web connection, a feature absent in many competing APIs that rely solely on training data. This approach could prove particularly valuable for enterprises requiring current information, although it may face challenges in applications requiring deterministic outputs.

Perplexity’s two-tier API offering shows the feature differences between Sonar Pro (left) and the base Sonar service (right), with Pro featuring enhanced citation capability and support for complex queries. (Credit: Perplexity)

Disruptive pricing: Affordable AI search for the enterprise market

The launch comes at a pivotal moment in the AI industry, when companies are increasingly seeking ways to integrate AI search capabilities into their products. With recent benchmarks showing Sonar Pro achieving an 85.8 F-score on the SimpleQA benchmark — significantly outperforming GPT-4o and Claude — Perplexity appears positioned to capitalize on growing enterprise demand for accurate, citation-backed AI responses.

The timing of this launch comes as Perplexity demonstrates significant market momentum, having just secured a $500 million funding round led by Institutional Venture Partners, which valued the company at $9 billion. This strategy could prove particularly effective as enterprises increasingly prioritize AI tools that provide verifiable, current information over black-box solutions.

For technical decision makers, Sonar’s launch represents a new option in the AI toolkit, particularly for applications requiring real-time information access and citation tracking. However, the true test will be whether Perplexity can maintain its performance edge and pricing advantage as larger competitors inevitably adjust their strategies."
OpenAI Stargate is a $500B bet: America’s AI Manhattan Project or costly dead end?,https://venturebeat.com/ai/openai-stargate-is-a-500b-bet-americas-ai-manhattan-project-or-costly-dead-end/,2025-01-22 16:38:00+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

In case you missed it amid the flurry of executive orders coming out of the White House in the days since President Trump returned to office for his second non-consecutive term this week, the single largest investment in AI infrastructure was just announced yesterday afternoon. Known as “the Stargate Project,” it’s a $500 billion (half a trillion) effort from OpenAI, SoftBank, Oracle and MGX to form a new venture that will build “new AI infrastructure for OpenAI in the United States,” and as OpenAI put it in its announcement post on the social network X, to “support the re-industrialization of the United States… also provide a strategic capability to protect the national security of America and its allies.”

The end goal: to build artificial general intelligence (AGI), or AI that outperforms humans on most economically valuable work, which has been OpenAI’s goal from the start — and ultimately, artificial superintelligence, or AI even smarter than humans can comprehend.

Flanked by Trump himself, OpenAI cofounder and CEO Sam Altman appeared at the White House alongside Softbank CEO Masayoshi “Masa” Son and Oracle executive chairman Larry Ellison, saying “I’m thrilled we get to do this in the United States of America. I think this will be the most important project of this era — and as Masa said, for AGI to get built here, to create hundreds of thousands of jobs, to create a new industry centered here — we wouldn’t be able to do this without you, Mr. President.”

Son called it “the beginning of our Golden Age.”

Several high-profile technology companies have partnered with the initiative to build and operate the infrastructure. Arm, Microsoft, Nvidia, Oracle and OpenAI are among the key partners contributing their expertise and resources to the effort. Oracle, Nvidia and OpenAI, in particular, will collaborate closely on developing the computing systems essential for the project’s success.

While some see the Stargate Project as a transformative investment in the future of AI, critics argue that it is a costly overreach, unnecessary in light of the rapid rise of leaner, open-source reasoning AI models like China’s DeepSeek R-1, which was just released earlier this week under a permissive MIT License — allowing it to be downloaded, fine-tuned or retrained, and used freely in commercial and noncommercial projects — and which matches or outperforms OpenAI’s own o1 reasoning models on key third-party benchmarks.

The debate has become a lightning rod for competing visions of AI development and the geopolitical dynamics shaping the race for technological supremacy.

A transformational leap forward?

For many advocates, the Stargate Project represents an unparalleled commitment to innovation and national competitiveness, on par with prior eras of large infrastructure spending such as the U.S. highway system during the Eisenhower era (though of course, that was with public funds — not private as in this case).

On X, AI commentator and former engineer David Shapiro said, “America just won geopolitics for the next 50 years with Project Stargate,” and likened the initiative to historic achievements like the Manhattan Project and NASA’s Apollo program.

He argued that this level of investment in artificial intelligence is not only necessary but inevitable, given the stakes. Shapiro described the project as a strategic move to ensure that America maintains technological supremacy, framing the investment as critical to solving global problems, driving economic growth and securing national security. “When America decides something matters and backs it with this kind of money? It happens. Period,” he declared.

In terms of practical applications, advocates point to the Stargate Project’s promise of AI-enabled breakthroughs in areas like cancer research, personalized medicine, and pandemic prevention.

Oracle’s Ellison has specifically highlighted the potential to develop new personalized mRNA-based vaccines and cancer treatments, revolutionizing healthcare.

A waste of (as yet un-procured) moneys?

Despite this optimism, critics are challenging the project on multiple fronts, from its financial feasibility to its strategic direction.

Elon Musk, head of the Department of Government Efficiency (DOGE) under President Donald Trump’s second administration and an OpenAI cofounder, cast doubt on the project’s funding.

Musk, who has since launched his own AI company, xAI, and its Grok language model family, posted on his social network, X, “They don’t actually have the money,” alleging that SoftBank — Stargate’s primary financial backer — has secured “well under $10B.”

In response, Altman replied this morning: “[I] genuinely respect your accomplishments and think you are the most inspiring entrepreneur of our time,” later writing that Musk was “wrong, as you surely know. want to come visit the first site already under way? this is great for the country. i realize what is great for the country isn’t always what’s optimal for your companies, but in your new role i hope you’ll mostly put [US flag emoji] first.”

Others have questioned the timing and strategic rationale behind the initiative. Tech entrepreneur and commentator Arnaud Bertrand took to X to contrast OpenAI’s infrastructure-heavy approach with the leaner, more decentralized strategy employed by China’s High-Flyer Capital Management, creators of the new, highest performing open-source large language model (LLM), DeepSeek-R1, released earlier this week.

Bertrand noted that DeepSeek has achieved performance parity with OpenAI’s latest models at just 3% of the cost, using far smaller GPU clusters and data centers.

He described the divergence as a collision of philosophies, with OpenAI betting on massive centralized infrastructure while DeepSeek pursues democratized, cost-efficient AI development.

“A fundamental question remains,” Bertrand wrote on X. “What will OpenAI customers be paying for exactly if much cheaper DeepSeek matches their latest models’ performance? Having spent an indecent amount of money on data centers isn’t a customer benefit in and of itself.”

Bertrand further argued that OpenAI’s focus on infrastructure may represent outdated thinking. “This $500B bet on infrastructure may be OpenAI fighting the last war,” he warned, pointing to DeepSeek’s success as evidence that innovation and agility — not scale — are the key drivers of modern AI progress.

The big philosophical divide: Will centralized or decentralized AI win out in the end?

At its core, the Stargate debate reflects a deeper philosophical divide about the future of AI. Proponents of the project argue that massive centralized infrastructure is essential to unlock artificial general intelligence (AGI) and tackle the world’s most pressing challenges. They view Stargate as a strategic imperative for maintaining U.S. global leadership in technology, especially in the face of rising competition from China.

Critics, however, question whether such centralization is necessary — or even viable — in an era when decentralized and open-source approaches are yielding increasingly competitive results. Bertrand, for example, compared the current AI race to the rivalry between Apple and Microsoft in the 1980s and 1990s.

Apple’s vertically integrated, premium ecosystem ultimately lost market dominance to Microsoft’s commoditized and widely accessible operating systems. He suggested that OpenAI’s customers may similarly gravitate toward more affordable alternatives like DeepSeek if the performance gap continues to narrow.

The debate over the Stargate Project extends beyond the tech industry, touching on national and global policy issues. Advocates see it as a necessary investment to ensure the U.S. retains its technological edge and addresses existential challenges like climate change, healthcare, and economic inequality. Skeptics worry it may divert resources from more effective and inclusive AI strategies, particularly as open-source models gain momentum.

The involvement of figures like Elon Musk, who occupies a unique position as both a government insider and a competitor to OpenAI through his xAI startup, adds further complexity to the discourse, as it challenges the project from within the same seat of power from which it was announced.

The Stargate Project is undeniably one of the most ambitious undertakings in the history of artificial intelligence, but its ultimate impact remains uncertain. If successful, it could reindustrialize the U.S. economy, secure American dominance in AI, and drive transformative breakthroughs across multiple industries. If its critics are correct, however, it could be remembered as a costly misstep — an investment that failed to anticipate the rise of leaner, more decentralized AI models.

As construction begins in Texas, the philosophical and strategic divide between centralized and decentralized approaches to AI has never been more pronounced. The stakes are enormous, and the outcome of this debate could shape the trajectory of artificial intelligence — and global power — for decades to come. For now, the world watches as America’s most ambitious AI initiative takes its first steps, while challengers like China’s DeepSeek continue to quietly rewrite the rules of the game."
Gaming comedy Mythic Quest Season 4 debuts on January 29 on Apple TV+,https://venturebeat.com/games/gaming-comedy-mythic-quest-season-4-debuts-on-january-29-on-apple-tv/,2025-01-24 23:16:00+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

Season 4 of a TV show is not something I write about very often, given my focus is video games. But Season 4 of Mythic Quest is another matter.

Debuting with the first two episodes on January 29 on Apple TV+, the show brings back the workplace comedy about a video game studio. The ensemble cast returns with stars including Rob McElhenney (as the mercurial creative director Ian Grimm) and Charlotte Nicdao (tech leader Poppy Li) and more. The show is good at skewering the sometimes ridiculous culture of video game industry, and it’s on the mark as it was originally created by Ubisoft.

The show is silly as usual, but I like how one of the opening scenes is about Play Pen, a user-generated content gimmick aimed at reviving the studio’s core online game. By the second episode, the users are all busy making sex games and the studio has to figure out what to do about it. David enlists the help of the studio’s ethics committee to find the answer. And, of course, AI is the next big trend that gets skewered in the show.

Game tester Rachel (played by Ashly Burch) has now been appointed the head of monetization for the studio. She will be hard-pressed to be more evil than Brad Bakshi (played by Dani Pudi) at making money.

The studio’s boss David Brittlesbee (played by David Hornsby, executive producer) continues to be caught in between the studio leads and the corporate headquarters. It’s still all-too-real when it comes to references to silly things in the game industry. Under preview, I’ve been checking it out.

The opening show, Boundaries, spells out the new responsibilities and boundary lines being drawn by the characters as their lives change. Ian and Poppy have rejoined the studio after striking out on their own. But Poppy, ever the programming workaholic, now isn’t working as hard because she has a new boyfriend. It’s interesting in that the show recognizes real-world game development problems, like too much crunch, or long work hours, often unpaid. So, of course, Poppy creates an AI version of herself to do work for her and help Ian with his middle-of-the-night strokes of brilliance.

The season will have 10 episodes, with the final one dropping on Apple TV+ on March 26.

Mythic Quest is executive produced by McElhenney and Charlie Day under their RCG banner, Michael Rotenberg and Nicholas Frenkel on behalf of 3Arts, and Margaret Boykin, Austin Dill, and Gérard Guillemot for Ubisoft Film & Television. Hornsby and Megan Ganz also executive produce. The series is produced for Apple TV+ by Lionsgate, 3 Arts Entertainment and Ubisoft. The first three seasons of Mythic Quest are now streaming globally on Apple TV+.

In the new season, the show also has an expansion of the Mythic Quest universe, Side Quest, which explores the lives of employees, players and fans who are impacted by the game in an anthology format. If you need a rest from CNN/Fox News all the time and our current political landscape, I recommend Mythic Quest as a nice diversion."
Tech leaders respond to the rapid rise of DeepSeek,https://venturebeat.com/ai/tech-leaders-respond-to-the-rapid-rise-of-deepseek/,2025-01-24 21:10:39+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

If you hadn’t heard, there’s a new AI star in town: DeepSeek, the subsidiary of Hong Kong-based quantitative analysis (quant) firm High-Flyer Capital Management, has sent shockwaves throughout Silicon Valley and the wider world with its release earlier this week of a new open source large reasoning model, DeepSeek R1, which matches OpenAI’s most powerful available model o1 — and at a fraction of the cost to users and to the company itself (when training it).

While the advent of DeepSeek R1 has already reshuffled a consistently topsy turvy, fast moving, intensely competitive market for new AI models — previous months saw OpenAI jockeying with Anthropic and Google for the most powerful proprietary models available, while Meta Platforms often came in with “close enough” open source rivals — the difference this time is the company behind the hot model is based in China, the geopolitical “frenemy” of the U.S., and whose tech sector was widely viewed, until this moment, as inferior to that of Silicon Valley.

As such, it’s caused no shortage of hand-wringing and existentialism from U.S. and western bloc techies, who are suddenly doubting OpenAI and the general big tech strategy of throwing more money and more compute (graphics processing units, GPUs, the powerful gaming chips typically used to train AI models) toward the problem of inventing ever more powerful models.

Yet some Western tech leaders have had a largely positive public response to DeepSeek’s rapid ascent.

Marc Andreessen, a co-inventor of the pioneering Mosaic web browser, co-founder of the Netscape browser company and current general partner at the famed Andreessen Horowitz (a16z) venture capital firm, posted on X today: “Deepseek R1 is one of the most amazing and impressive breakthroughs I’ve ever seen — and as open source, a profound gift to the world [robot emoji, salute emoji].”

Yann LeCun, the Chief AI Scientist for Meta’s Fundamental AI Research (FAIR) division, posted on his LinkedIn account:

“To people who see the performance of DeepSeek and think:

‘China is surpassing the US in AI.’

You are reading this wrong.

The correct reading is:

‘Open source models are surpassing proprietary ones.’



DeepSeek has profited from open research and open source (e.g. PyTorch and Llama from Meta)

They came up with new ideas and built them on top of other people’s work.

Because their work is published and open source, everyone can profit from it.

That is the power of open research and open source.”

And even Mark “Zuck” Zuckerberg, Meta AI’s founder and CEO, seemed to seek to counter the rise of DeepSeek with his own post on Facebook promising that a new version of Facebook’s open source AI model family Llama would be “the leading state of the art model” when it is released sometime this year. As he put it:

“This will be a defining year for AI. In 2025, I expect Meta AI will be the leading assistant serving more than 1 billion people, Llama 4 will become the leading state of the art model, and we’ll build an AI engineer that will start contributing increasing amounts of code to our R&D efforts. To power this, Meta is building a 2GW+ datacenter that is so large it would cover a significant part of Manhattan. We’ll bring online ~1GW of compute in ’25 and we’ll end the year with more than 1.3 million GPUs. We’re planning to invest $60-65B in capex this year while also growing our AI teams significantly, and we have the capital to continue investing in the years ahead. This is a massive effort, and over the coming years it will drive our core products and business, unlock historic innovation, and extend American technology leadership. Let’s go build!“

He even shared a graphic showing the 2 gigawatt datacenter mentioned in his post overlaid on Manhattan:

Clearly, even as he espouses a commitment to open source AI, Zuck is not convinced that DeepSeek’s approach of optimizing for efficiency while leveraging far fewer GPUs than major labs is the right one for Meta, or for the future of AI.

But with U.S. companies raising and/or spending record sums on new AI infrastructure that many experts have noted depreciate rapidly (due to hardware/chip and software advancements), the question remains which vision of the future will win out in the end to become the dominant AI provider for the world. Or maybe it will always be a multiplicity of models each with a smaller market share? Stay tuned, because this competition is getting closer and fiercer than ever."
How a top Chinese AI model overcame US sanctions,https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/,2025-01-24 00:00:00,"“This could be a truly equalizing breakthrough that is great for researchers and developers with limited resources, especially those from the Global South,” says Hancheng Cao, an assistant professor in information systems at Emory University.

DeepSeek’s success is even more remarkable given the constraints facing Chinese AI companies in the form of increasing US export controls on cutting-edge chips. But early evidence shows that these measures are not working as intended. Rather than weakening China’s AI capabilities, the sanctions appear to be driving startups like DeepSeek to innovate in ways that prioritize efficiency, resource-pooling, and collaboration.

To create R1, DeepSeek had to rework its training process to reduce the strain on its GPUs, a variety released by Nvidia for the Chinese market that have their performance capped at half the speed of its top products, according to Zihan Wang, a former DeepSeek employee and current PhD student in computer science at Northwestern University.

DeepSeek R1 has been praised by researchers for its ability to tackle complex reasoning tasks, particularly in mathematics and coding. The model employs a “chain of thought” approach similar to that used by ChatGPT o1, which lets it solve problems by processing queries step by step.

Dimitris Papailiopoulos, principal researcher at Microsoft’s AI Frontiers research lab, says what surprised him the most about R1 is its engineering simplicity. “DeepSeek aimed for accurate answers rather than detailing every logical step, significantly reducing computing time while maintaining a high level of effectiveness,” he says."
The US withdrawal from the WHO will hurt us all,https://www.technologyreview.com/2025/01/24/1110480/us-withdrawal-from-who-will-hurt-us-all/,2025-01-24 00:00:00,"The US is the biggest donor to the WHO, and the loss of this income is likely to have a significant impact on the organization, which develops international health guidelines, investigates disease outbreaks, and acts as an information-sharing hub for member states.

But the US will also lose out. “It’s a very tragic and sad event that could only hurt the United States in the long run,” says William Moss, an epidemiologist at Johns Hopkins Bloomberg School of Public Health in Baltimore.

Trump appears to take issue with the amount the US donates to the WHO. He points out that it makes a much bigger contribution than China, a country with a population four times that of the US. “It seems a little unfair to me,” he said as he prepared to sign the executive order.

It is true that the US is far and away the biggest financial supporter of the WHO. The US contributed $1.28 billion over the two-year period covering 2022 and 2023. By comparison, the second-largest donor, Germany, contributed $856 million in the same period. The US currently contributes 14.5% of the WHO’s total budget.

But it’s not as though the WHO sends a billion-dollar bill to the US. All member states are required to pay membership dues, which are calculated as a percentage of a country’s gross domestic product. For the US, this figure comes to $130 million. China pays $87.6 million. But the vast majority of the US’s contributions to the WHO are made on a voluntary basis—in recent years, the donations have been part of multibillion-dollar spending on global health by the US government. (Separately, the Bill and Melinda Gates Foundation contributed $830 million over 2022 and 2023.)

There’s a possibility that other member nations will increase their donations to help cover the shortfall left by the US’s withdrawal. But it is not clear who will step up—or what implications it will have to change the structure of donations."
Why the next energy race is for underground hydrogen,https://www.technologyreview.com/2025/01/23/1110435/geologic-hydrogen/,2025-01-23 00:00:00,"I’ve been thinking about underground resources a lot this week, since I’ve been reporting a story about a new startup, Addis Energy. The company is looking to use subsurface rocks, and the conditions down there, to produce another useful chemical: ammonia. In an age of lab-produced breakthroughs, it feels like something of a regression to go digging for resources, but looking underground could help meet energy demand while also addressing climate change.

It’s rare that hydrogen turns up in oil and gas operations, and for decades, the conventional wisdom has been that there aren’t large deposits of the gas underground. Hydrogen molecules are tiny, after all, so even if the gas was forming there, the assumption was that it would just leak out.

However, there have been somewhat accidental discoveries of hydrogen over the decades, in abandoned mines or new well sites. There are reports of wells that spewed colorless gas, or flames that burned gold. And as people have looked more intentionally for hydrogen, they’ve started to find it.

As it turns out, hydrogen tends to build up in very different rocks from those that host oil and gas deposits. While fossil-fuel prospecting tends to focus on softer rocks, like organic-rich shale, hydrogen seems most plentiful in iron-rich rocks like olivine. The gas forms when chemical reactions at elevated temperature and pressure underground pull water apart. (There’s also likely another mechanism that forms hydrogen underground, called radiolysis, where radioactive elements emit radiation that can split water.)

Some research has put the potential amount of hydrogen available at around a trillion tons—plenty to feed our demand for centuries, even if we ramp up use of the gas.

The past few years have seen companies spring up around the world to try to locate and tap these resources. There’s an influx in Australia, especially the southern part of the country, which seems to have conditions that are good for making hydrogen. One startup, Koloma, has raised over $350 million to aid its geologic hydrogen exploration.

There are so many open questions for this industry, including how much hydrogen is actually going to be accessible and economical to extract. It’s not even clear how best to look for the gas today; researchers and companies are borrowing techniques and tools from the oil and gas industry, but there could be better ways.

It’s also unknown how this could affect climate change. Hydrogen itself may not warm the planet, but it can contribute indirectly to global warming by extending the lifetime of other greenhouse gases. It’s also often found with methane, a super-powerful greenhouse gas that could do major harm if it leaks out of operations at a significant level."
OpenAI has upped its lobbying efforts nearly sevenfold,https://www.technologyreview.com/2025/01/21/1110260/openai-ups-its-lobbying-efforts-nearly-seven-fold/,2025-01-21 00:00:00,"OpenAI did not respond to questions about its lobbying efforts.

But perhaps more important, the disclosure is a clear signal of the company’s arrival as a political player, as its first year of serious lobbying ends and Republican control of Washington begins. While OpenAI’s lobbying spending is still dwarfed by its peers’—Meta tops the list of Big Tech spenders, with more than $24 million in 2024—the uptick comes as it and other AI companies have helped redraw the shape of AI policy.

For the past few years, AI policy has been something like a whack-a-mole response to the risks posed by deepfakes and misinformation. But over the last year, AI companies have started to position the success of the technology as pivotal to national security and American competitiveness, arguing that the government must therefore support the industry’s growth. As a result, OpenAI and others now seem poised to gain access to cheaper energy, lucrative national security contracts, and a more lax regulatory environment that’s unconcerned with the minutiae of AI safety.

While the big players seem more or less aligned on this grand narrative, messy divides on other issues are still threatening to break through the harmony on display at President Trump’s inauguration this week.

AI regulation really began in earnest after ChatGPT launched in November 2022. At that point, “a lot of the conversation was about responsibility,” says Liana Keesing, campaigns manager for technology reform at Issue One, a democracy nonprofit that tracks Big Tech’s influence.

Companies were asked what they’d do about sexually abusive deepfake images and election disinformation. “Sam Altman did a very good job coming in and painting himself early as a supporter of that process,” Keesing says.

OpenAI started its official lobbying effort around October 2023, hiring Chan Park—a onetime Senate Judiciary Committee counsel and Microsoft lobbyist—to lead the effort. Lawmakers, particularly then Senate majority leader Chuck Schumer, were vocal about wanting to curb these particular harms; OpenAI hired Schumer’s former legal counsel, Reginald Babin, as a lobbyist, according to data from OpenSecrets. This past summer, the company hired the veteran political operative Chris Lehane as its head of global policy.

OpenAI’s previous disclosures confirm that the company’s lobbyists subsequently focused much of last year on legislation like the No Fakes Act and the Protect Elections from Deceptive AI Act. The bills did not materialize into law. But as the year went on, the regulatory goals of AI companies began to change. “One of the biggest shifts that we’ve seen,” Keesing says, “is that they’ve really started to focus on energy.”"
What’s next for robots,https://www.technologyreview.com/2025/01/23/1110496/whats-next-for-robots/,2025-01-23 00:00:00,"“But those are expensive to create and time consuming, so you can only do a limited number of them,” says Rev Lebaredian, vice president of simulation technologies at Nvidia. Cosmos can instead take a handful of those examples and create a three-dimensional simulation of a hospital. It will then start making changes—different floor colors, different sizes of hospital beds—and create slightly different environments. “You’ll multiply that data that you captured in the real world millions of times,” Lebaredian says. In the process, the model will be fine-tuned to work well in that specific hospital setting.

It’s sort of like learning both from your experiences in the real world and from your own imagination (stipulating that your imagination is still bound by the rules of physics).

Teaching robots through AI and simulations isn’t new, but it’s going to become much cheaper and more powerful in the years to come.

A smarter brain gets a smarter body

Plenty of progress in robotics has to do with improving the way a robot senses and plans what to do—its “brain,” in other words. Those advancements can often happen faster than those that improve a robot’s “body,” which determine how well a robot can move through the physical world, especially in environments that are more chaotic and unpredictable than controlled assembly lines.

The military has always been keen on changing that and expanding the boundaries of what’s physically possible. The US Navy has been testing machines from a company called Gecko Robotics that can navigate up vertical walls (using magnets) to do things like infrastructure inspections, checking for cracks, flaws, and bad welding on aircraft carriers.

There are also investments being made for the battlefield. While nimble and affordable drones have reshaped rural battlefields in Ukraine, new efforts are underway to bring those drone capabilities indoors. The defense manufacturer Xtend received an $8.8 million contract from the Pentagon in December 2024 for its drones, which can navigate in confined indoor spaces and urban environments. These so-called “loitering munitions” are one-way attack drones carrying explosives that detonate on impact.

“These systems are designed to overcome challenges like confined spaces, unpredictable layouts, and GPS-denied zones,” says Rubi Liani, cofounder and CTO at Xtend. Deliveries to the Pentagon should begin in the first few months of this year.

Another initiative—sparked in part by the Replicator project, the Pentagon’s plan to spend more than $1 billion on small unmanned vehicles—aims to develop more autonomously controlled submarines and surface vehicles. This is particularly of interest as the Department of Defense focuses increasingly on the possibility of a future conflict in the Pacific between China and Taiwan. In such a conflict, the drones that have dominated the war in Ukraine would serve little use because battles would be waged almost entirely at sea, where small aerial drones would be limited by their range. Instead, undersea drones would play a larger role."
Anthropic plans to release a ‘two-way’ voice mode for Claude,https://techcrunch.com/2025/01/21/anthropic-plans-to-release-a-two-way-voice-mode-for-claude/,2025-01-21 00:00:00,"In Brief

Anthropic CEO Dario Amodei says that the company plans to release a “two-way” voice mode for its chatbot, Claude, as well as a memory feature that lets Claude remember more about users and past conversations.

Speaking to The Wall Street Journal at the World Economic Forum at Davos, Amodei also revealed that Anthropic expects to release “smarter” AI models in the coming months, and that the company has been “overwhelmed” by the “surge in demand” in the last year.

“The surge in demand we’ve seen over the last year, and particularly in the last three months, has overwhelmed our ability to provide the needed compute,” Amodei said.

Anthropic is racing to keep pace with its chief AI rival, OpenAI, in an extremely capital-intensive sector. Despite having raised $13.7 billion in capital to date, Anthropic reportedly lost billions of dollars last year. Anthropic is said to be in talks to raise another ~$2 billion at a $60 billion valuation."
Trump signs exec order delaying TikTok enforcement action for 75 days,https://techcrunch.com/2025/01/20/trump-signs-exec-order-delaying-tiktok-enforcement-action-for-75-days/,2025-01-20 00:00:00,"In Brief

President Donald Trump has signed an executive order aimed at restoring TikTok service in the U.S.

The order instructs relevant government agencies to “pursue a resolution” that “protects national security” while “saving [TikTok.]” Via the order, Trump is instructing the U.S. attorney general not to take any action for 75 days to enforce the Protecting Americans from Foreign Adversary Controlled Applications Act (PAFACA), the act that effectively banned TikTok in the U.S. on Sunday, January 19.

“During this period, the Department of Justice shall take no action to enforce the Act or impose any penalties against any entity for any noncompliance with the Act,” the executive order reads. “Even after the expiration of the above-specified period, the Department of Justice shall not take any action to enforce the Act […]”

Trump’s move comes on the heels of a U.S. Supreme Court decision to uphold the PAFACA, which passed with bipartisan congressional support during former President Joe Biden’s term."
Mistral AI plans IPO,https://techcrunch.com/2025/01/21/mistral-ai-plans-ipo/,2025-01-21 00:00:00,"In Brief

French AI lab Mistral is working toward an initial public offering, co-founder and CEO Arthur Mensch said Tuesday in an interview with Bloomberg at the World Economic Forum in Davos.

Mistral is “not for sale,” Mensch said, adding that the company plans to open an office in Singapore to focus on the Asia-Pacific region and is growing in Europe and the U.S. “Of course, [an IPO is] the plan.”

Mistral, which Mensch launched in 2023 alongside former researchers from Google’s DeepMind and Meta, is often described as Europe’s answer to U.S. incumbents like OpenAI. The lab releases AI models and services that compete with offerings from OpenAI and others, including a ChatGPT-like platform called Le Chat.

Mistral has raised around $1.14 billion in capital to date from investors including Andreessen Horowitz, General Catalyst, and Lightspeed Venture Partners. The company was reportedly last valued at around $6 billion."
President Trump repeals Biden’s AI executive order,https://techcrunch.com/2025/01/20/president-trump-repeals-bidens-ai-executive-order/,2025-01-20 00:00:00,"In Brief

During his first day in office, President Donald Trump revoked a 2023 executive order signed by former President Joe Biden that sought to reduce the potential risks AI poses to consumers, workers, and national security.

Biden’s executive order directed the Commerce Department’s National Institute of Standards and Technology (NIST) to author guidance that helps companies identify — and correct for — flaws in models, including biases. The executive order also required developers of AI systems to share the results of safety tests with the U.S. government before they were released to the public.

Critics allied with Trump argued that the executive order’s reporting requirements were onerous and effectively forced companies to disclose their trade secrets. During his campaign, Trump promised policies that would “support AI development rooted in free speech and human flourishing” — but declined to go into detail."
OpenAI’s agent tool may be nearing release,https://techcrunch.com/2025/01/20/openais-agent-tool-may-be-nearing-release/,2025-01-20 00:00:00,"OpenAI may be close to releasing an AI tool that can take control of your PC and perform actions on your behalf.

Tibor Blaho, a software engineer with a reputation for accurately leaking upcoming AI products, claims to have uncovered evidence of OpenAI’s long-rumored Operator tool. Publications including Bloomberg have previously reported on Operator, which is said to be an “agentic” system capable of autonomously handling tasks like writing code and booking travel.

According to The Information, OpenAI is targeting January as Operator’s release month. Code uncovered by Blaho this weekend adds credence to that reporting.

OpenAI’s ChatGPT client for macOS has gained options, hidden for now, to define shortcuts to “Toggle Operator” and “Force Quit Operator,” per Blaho. And OpenAI has added references to Operator on its website, Blaho said — albeit references that aren’t yet publicly visible.

According to Blaho, OpenAI’s site also contains not-yet-public tables comparing the performance of Operator to other computer-using AI systems. The tables may well be placeholders. But if the numbers are accurate, they suggest that Operator isn’t 100% reliable, depending on the task.

On OSWorld, a benchmark that tries to mimic a real computer environment, “OpenAI Computer Use Agent (CUA)” — possibly the AI model powering Operator — scores 38.1%, ahead of Anthropic’s computer-controlling model but well short of the 72.4% humans score. OpenAI CUA surpasses human performance on WebVoyager, which evaluates an AI’s ability to navigate and interact with websites. But the model falls short of human-level scores on another web-based benchmark, WebArena, according to the leaked benchmarks.

Operator also struggles with tasks a human could perform easily, if the leak is to be believed. In a test that tasked Operator with signing up with a cloud provider and launching a virtual machine, Operator was only successful 60% of the time. Tasked with creating a Bitcoin wallet, Operator succeeded only 10% of the time.

We’ve reached out to OpenAI for comment and will update this piece if we hear back.

OpenAI’s imminent entry into the AI agent space comes as rivals, including the aforementioned Anthropic, Google, and others, make plays for the nascent segment. AI agents may be risky and speculative, but tech giants are already touting them as the next big thing in AI. According to analytics firm Markets and Markets, the market for AI agents could be worth $47.1 billion by 2030.

Agents today are rather primitive. But some experts have raised concerns about their safety, should the technology rapidly improve.

One of the leaked charts shows Operator performing well on selected safety evaluations, including tests that try to get the system to perform “illicit activities” and search for “sensitive personal data.” Reportedly, safety testing is among the reasons for Operator’s long development cycle. In a recent X post, OpenAI co-founder Wojciech Zaremba criticized Anthropic for releasing an agent he claims lacks safety mitigations.

“I can only imagine the negative reactions if OpenAI made a similar release,” Zaremba wrote.

It’s worth noting that OpenAI has been criticized by AI researchers, including ex-staff, for allegedly de-emphasizing safety work in favor of quickly productizing its technology.

TechCrunch has an AI-focused newsletter! Sign up here to get it in your inbox every Wednesday."
