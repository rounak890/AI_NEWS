title,link,publish_date,content
Sustainability is key in 2025 for businesses to advance AI efforts,https://www.artificialintelligence-news.com/news/sustainability-key-in-2025-businesses-advance-ai-efforts/,2025-02-04 14:44:43+00:00,"Since AI hit the mainstream in the last few years, industries across the world are feeling the positive impacts. From helping humanity to clean up our oceans to helping doctors to detect cancers earlier than ever before , AI’s potential and impact are growing by the day.

Regardless of whether this is being powered via a supercomputer, edge computing methods, or a traditional data centre, society is truly feeling the positive effect of advances in the AI industry.

However, with fresh innovation has always come questions around environmental impact. These concerns are gaining momentum, especially around the energy consumption associated with the increased processing power required to run increasingly large systems.

The United Nations Environment Programme recently expressed concerns about the rising levels of e-waste and cooling considerations for data centres more specifically. This also follows on from similar concerns from academia , who have flagged that a larger carbon footprint might be the price we are paying for innovation.

Add on top of this the fact that governments globally are implementing new regulations and reporting requirements as part of initiatives to curb the impact of climate change, such as the EU’s Circular Economy Action Plan (CEAP), and it becomes clear this issue is coming to the forefront of the AI agenda.

Analysts around the globe are also beginning to focus on this, with Gartner naming energy-efficient computing as a top technology trend for 2025 , as organisations come under pressure to show they are considering the impact AI is having on the environment.

Businesses that are not considering sustainability as part of core AI infrastructure and expansion or technology strategies are at risk of hindering their own progress. Failing to keep pace with sustainable practices can cause reputational damage, as organisations may be seen as behind the curve in an increasingly sustainability-focused world, alongside risking non-compliance with regulation.

When looking at the previously mentioned example of e-waste, if organisations are found to be not properly recycling devices (such as our Global Take Back Service ), they could face negative feedback and lose business as a result of poor brand image. With these factors in mind, it’s clear that businesses must consider building a sustainable AI framework that supports operational efficiency, encouraging business growth.

Prioritising the implementation of technologies that limit energy consumption can be a huge help when it comes to ensuring regulatory compliance and the ability to meet greater sustainability goals. These also come with the ability to help organisations to future-proof against market instability with reduced reliance on energy along with strengthening brand reputation in an increasingly environmentally-conscious world.

This is within easy reach for many businesses as there is a large number of offerings in the market that can balance sustainability efforts, with high processing capabilities. At ASUS we have partnered with Intel to provide servers that prioritise energy efficiency . There is so much available to businesses today if they choose to take the initial step and consider a strategy to implement technologies which balance regulatory pressures, customer expectations, and overall business goals will help organisations to feel confident innovation won’t come at a cost to the environment.

IDC has raised this with its audience, recently releasing predictions on the technology industry which outlined; “To address the environmental challenges of harnessing AI’s benefits, enterprises are turning to Sustainable AI Frameworks that focus on minimising the environmental impact of artificial intelligence by addressing key elements such as energy efficiency, resource optimisation, and e-waste reduction.”

As AI innovation continues to grow, alongside market pressure, businesses will find it becomes clear which organisations within the market are able to cope, and which will be left behind. Ultimately, those who choose to embed sustainability into AI strategies will lead the way.

(Photo by Angela Benito)

See also: French initiative for responsible AI leaders

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
Zebra Technologies and enterprise AI in the APAC,https://www.artificialintelligence-news.com/news/zebra-technologies-and-enterprise-ai-in-the-apac/,2025-02-04 14:43:12+00:00,"Enterprise AI transformation is reaching a tipping point. In the Asia Pacific, Zebra Technologies has unveiled ambitious plans to change frontline operations across the region. At a time when CISQ estimates poor software quality will cost US businesses $2.41 trillion in 2022, the push for practical, results-driven AI implementation is urgent.

“Elements of our three-pillar strategy have been around for quite some time, but what’s revolutionising the frontline today is intelligent automation,” Tom Bianculli, Chief Technology Officer at Zebra Technologies, told reporters at a briefing during Zebra’s 2025 Kickoff in Perth, Australia last week. “We’re not just digitising workflows – we’re connecting wearable technology with robotic workflows, enabling frontline workers to seamlessly interact with automation in ways that were impossible just five years ago.”

Practical applications driving change

The real-world impact of enterprise AI transformation is already evident in Zebra’s recent collaboration with a major North American retailer. The solution combines traditional AI with generative AI capabilities, enabling fast shelf analysis and automated task generation.

“You snap a picture of a shelf, [and] within one second, the traditional AI identifies all the products on the shelf, identifies where there’s missing product, maybe misplaced product… and then it makes that information available to a Gen AI agent that then decides what should you do,” Bianculli explains.

This level of automation has demonstrated significant operational improvements, reducing staffing requirements at the retailer by 25%. When it detects missing stock, the system automatically generates tasks for the right personnel, streamlining what was previously a multi-step manual process.

APAC leading AI adoption

The Asia Pacific region is emerging as a frontrunner in enterprise AI transformation. IBM research presented at the briefing indicates that 54% of APAC enterprises now expect AI to deliver longer-term innovation and revenue generation benefits. The region’s AI investment priorities for 2025 are clearly defined:

– 21% focused on enhancing customer experiences

– 18% directed toward business process automation

– 16% invested in sales automation and customer lifecycle management

Ryan Goh, Senior Vice President and General Manager of Asia Pacific at Zebra Technologies, points to practical implementations that are already driving results: “We have customers in e-commerce using ring scanners to scan packages, significantly improving their productivity compared to traditional scanning methods.”

Innovation at the edge

Zebra’s approach to AI deployment encompasses:

– AI devices with native neural architecture for on-device processing

– Multimodal experiences that mirror human cognitive capabilities

– Gen AI agents optimising workload distribution between edge and cloud

The company is advancing its activities in edge computing, with Bianculli revealing plans for on-device language models. This innovation mainly targets environments where internet connectivity is restricted or prohibited, ensuring AI capabilities remain accessible regardless of network conditions.

Regional market dynamics

The enterprise AI transformation journey varies significantly across APAC markets. India’s landscape is particularly dynamic, with the country’s GDP projected to grow 6.6% and manufacturing expected to surge by 7% YOY. Its commitment to AI is evident, with 96% of organisations surveyed by WEF actively running AI programmes.

Japan presents a different scenario, with 1.2% projected GDP growth and some unique challenges to automation adoption. “We used to think that tablets are for retail, but the Bay Area proved us wrong,” Goh notes, highlighting unexpected applications in manufacturing and customer self-service solutions.

Future trajectory

Gartner’s projections indicate that by 2027, 25% of CIOs will implement augmented connected workforce initiatives that will halve the time required for competency development. Zebra is already moving in this direction with its Z word companion, which uses generative AI and large language models and is scheduled for pilot deployment with select customers in Q2 of this year.

With a global presence spanning 120+ offices in 55 countries and 10,000+ channel partners across 185 countries, Zebra is positioned play strongly in the enterprise AI transformation across APAC. As the region moves from AI experimentation to full-scale deployment, the focus remains on delivering practical innovations that drive measurable business outcomes and operational efficiency.

(Photo by )

See also: Walmart and Amazon drive retail transformation with AI

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here"
French initiative for responsible AI leaders,https://www.artificialintelligence-news.com/news/french-initiative-for-responsible-ai-leaders/,2025-02-04 13:17:12+00:00,"ESSEC Business School and Accenture have announced the launch of a new initiative, ‘AI for Responsible Leadership,’ which marks the 10th anniversary of the establishment of the role of Chair at ESSEC, titled the ESSEC Accenture Strategic Business Analytics Chair.

The initiative aims to encourage the use of artificial intelligence by leaders in ways that are responsible and ethical, and that lead to high levels of professional performance. It aims to provide current and future leaders with the skills they require when faced with challenges in the future; economic, environmental, or social.

Several organisations support the initiative, including institutions, businesses, and specialised groups, including ESSEC Metalab for Data, Technology & Society, and Accenture Research.

Executive Director of the ESSEC Metalab, Abdelmounaim Derraz, spoke of the collaboration, saying, “Technical subjects are continuing to shake up business schools, and AI has opened up opportunities for collaboration between partner companies, researchers, and other members of the ecosystem (students, think tanks, associations, [and] public service).”

ESSEC and Accenture aim to integrate perspectives from multiple fields of expertise, an approach that is a result of experimentation in the decade the Chair has existed.

The elements of the initiative include workshops and talks designed to promote the exchange of knowledge and methods. It will also include a ‘barometer’ to help track AI’s implementation and overall impact on responsible leadership.

The initiative will engage with a network of institutions and academic publications, and an annual Grand Prix will recognise projects that focus on and explore the subject of AI and leadership.

Fabrice Marque, founder of the initiative and the current ESSEC Accenture Strategics Business Analytics Chair, said, “For years, we have explored the potential of using data and artificial intelligence in organisations. The synergies we have developed with our partners (Accenture, Accor, Dataiku, Engie, Eurofins, MSD, Orange) allowed us to evaluate and test innovative solutions before deploying them.

“With this initiative, we’re taking a major step: bringing together an engaged ecosystem to sustainably transform how leaders think, decide, and act in the face of tomorrow’s challenges. Our ambition is clear: to make AI a lever for performance, innovation and responsibility for […] leaders.”

Managing Director at Accenture and sponsor of the ESSEC/Accenture Chair and initiative, Aurélien Bouriot, said, “The ecosystem will benefit from the resources that Accenture puts at its disposal, and will also benefit our employees who participate.”

Laetitia Cailleteau, Managing Director at Accenture and leader of Responsible AI & Generative AI for Europe, highlighted the importance of future leaders understanding all aspects of AI.

“AI is a pillar of the ongoing industrial transformation. Tomorrow’s leaders must understand the technical, ethical, and human aspects and risks – and know how to manage them. In this way, they will be able to maximise value creation and generate a positive impact for the organisation, its stakeholders and society as a whole.”

Image credit: Wikimedia Commons

See also: Microsoft and OpenAI probe alleged data theft by DeepSeek

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
ChatGPT gains agentic capability for complex research,https://www.artificialintelligence-news.com/news/chatgpt-gains-agentic-capability-for-complex-research/,2025-02-03 17:22:06+00:00,"OpenAI is releasing a powerful agentic capability that enables ChatGPT to conduct complex, multi-step research tasks online. The feature, called Deep Research, reportedly achieves in tens of minutes what could take a human researcher hours or even days.

OpenAI describes Deep Research as a significant milestone in its journey toward artificial general intelligence (AGI).

“The ability to synthesise knowledge is a prerequisite for creating new knowledge,” says OpenAI. “For this reason, Deep Research marks a significant step toward our broader goal of developing AGI.”

Agentic AI enables ChatGPT to assist with complex research

Deep Research empowers ChatGPT to find, analyse, and synthesise information from hundreds of online sources autonomously. With just a prompt from the user, the tool can deliver a comprehensive report, comparable to the output of a research analyst, according to OpenAI.

Drawing capabilities from a variant of OpenAI’s upcoming “o3” model, the aim is to free users from time-consuming, labour-intensive information gathering. Whether it’s a competitive analysis of streaming platforms, an informed policy review, or even personalised recommendations for a new commuter bike, Deep Research promises precise and reliable results.

Importantly, every output includes full citations and transparent documentation—enabling users to verify the findings with ease.

The tool appears particularly adept at uncovering niche or non-intuitive insights, making it an invaluable asset across industries like finance, science, policymaking, and engineering. But OpenAI also envisions Deep Research being useful for the average user, such as shoppers looking for hyper-personalised recommendations or a specific product.

This latest agentic capability operates through the user interface of ChatGPT; users simply select the “Deep Research” option in the message composer and type their query. Supporting files or spreadsheets can also be uploaded for additional context.

Once initiated, the AI embarks on a rigorous multi-step process, which may take 5-30 minutes to complete. A sidebar provides updates on the actions taken and the sources consulted. Users can carry on with other tasks and will be notified when the final report is ready.

The results are presented in the chat as detailed, well-documented reports. In the coming weeks, OpenAI plans to enhance these outputs further by embedding images, data visualisations, and graphs to deliver even greater clarity and context.

Unlike GPT-4o – which excels in real-time, multimodal conversations – Deep Research prioritises depth and detail. Its ability to rigorously cite sources and provide comprehensive analysis sets it apart—shifting the focus from fast, summarised answers to well-documented, research-grade insights.

Built for real-world challenges

Deep Rsearch leverages sophisticated training methodologies, grounded in real-world browsing and reasoning tasks across diverse domains. Its model was trained via reinforcement learning to autonomously plan and execute multi-step research processes, including backtracking and adaptively refining its approach as new information becomes available.

The tool can browse user-uploaded files, generate and iterate on graphs using Python, embed media such as generated images and web pages into responses, and cite exact sentences or passages from its sources. The result of this extensive training is a highly capable agent for tackling complex real-world problems.

OpenAI evaluated Deep Research across a broad set of expert-level exams known as “Humanity’s Last Exam”. The exams – comprising over 3,000 questions covering topics from rocket science and linguistics to ecology and classics – test an AI’s competence in solving multifaceted problems.

The results were impressive, with the model achieving a record-breaking 26.6% accuracy across these domains:

GPT-4o: 3.3%

Grok-2: 3.8%

Claude 3.5 Sonnet: 4.3%

OpenAI o1: 9.1%

DeepSeek-R1: 9.4%

Deep research: 26.6% (with browsing + Python tools)

Deep Research also reached a new state-of-the-art performance on the GAIA benchmark, which evaluates AI models on real-world questions requiring reasoning, multi-modal fluency, and tool-use proficiency. Deep Research topped the leaderboard with a score of 72.57%.

Limitations and challenges

While the Deep Research agentic AI capability in ChatGPT signifies a bold step forward, OpenAI acknowledges that the technology is still in its early stages and comes with limitations.

The system occasionally “hallucinates” facts or offers incorrect inferences, albeit at a notably reduced rate compared to existing GPT models, according to OpenAI. It also faces challenges in differentiating between authoritative sources and speculative content, and it struggles to calibrate its confidence levels—often displaying undue certainty for potentially uncertain findings.

Minor formatting errors in reports and citations, as well as delays in initiating tasks, could also frustrate initial users. OpenAI says these issues are expected to improve over time with more usage and iterative refinements.

OpenAI is rolling out the capability gradually, starting with Pro users, who will have access to up to 100 queries per month. Plus and Team tiers will follow suit, with Enterprise access arriving next.

UK, Swiss, and European Economic Area residents are not yet able to access the feature, but OpenAI says it’s working on expanding its rollout to these regions.

In the weeks ahead, OpenAI will expand the feature to ChatGPT’s mobile and desktop platforms. The long-term vision includes enabling connections to subscription-based or proprietary data sources, further enhancing the robustness and personalisation of its outputs.

Looking further ahead, OpenAI envisions integrating Deep Research with “Operator,” an existing chatbot capability that takes real-world actions. This integration would allow ChatGPT to seamlessly handle tasks that require both asynchronous online research and real-world execution.

(Photo by John Schnobrich)

See also: Microsoft and OpenAI probe alleged data theft by DeepSeek

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
Qwen 2.5-Max outperforms DeepSeek V3 in some benchmarks,https://www.artificialintelligence-news.com/news/qwen-2-5-max-outperforms-deepseek-v3-some-benchmarks/,2025-01-29 10:03:48+00:00,"Alibaba’s response to DeepSeek is Qwen 2.5-Max, the company’s latest Mixture-of-Experts (MoE) large-scale model.

Qwen 2.5-Max boasts pretraining on over 20 trillion tokens and fine-tuning through cutting-edge techniques like Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF).

With the API now available through Alibaba Cloud and the model accessible for exploration via Qwen Chat, the Chinese tech giant is inviting developers and researchers to see its breakthroughs firsthand.

Outperforming peers

When comparing Qwen 2.5-Max’s performance against some of the most prominent AI models on a variety of benchmarks, the results are promising.

Evaluations included popular metrics like the MMLU-Pro for college-level problem-solving, LiveCodeBench for coding expertise, LiveBench for overall capabilities, and Arena-Hard for assessing models against human preferences.

According to Alibaba, “Qwen 2.5-Max outperforms DeepSeek V3 in benchmarks such as Arena-Hard, LiveBench, LiveCodeBench, and GPQA-Diamond, while also demonstrating competitive results in other assessments, including MMLU-Pro.”

The instruct model – designed for downstream tasks like chat and coding – competes directly with leading models such as GPT-4o, Claude-3.5-Sonnet, and DeepSeek V3. Among these, Qwen 2.5-Max managed to outperform rivals in several key areas.

Comparisons of base models also yielded promising outcomes. While proprietary models like GPT-4o and Claude-3.5-Sonnet remained out of reach due to access restrictions, Qwen 2.5-Max was assessed against leading public options such as DeepSeek V3, Llama-3.1-405B (the largest open-weight dense model), and Qwen2.5-72B. Again, Alibaba’s newcomer demonstrated exceptional performance across the board.

“Our base models have demonstrated significant advantages across most benchmarks,” Alibaba stated, “and we are optimistic that advancements in post-training techniques will elevate the next version of Qwen 2.5-Max to new heights.”

Making Qwen 2.5-Max accessible

To make the model more accessible to the global community, Alibaba has integrated Qwen 2.5-Max with its Qwen Chat platform, where users can interact directly with the model in various capacities—whether exploring its search capabilities or testing its understanding of complex queries.

For developers, the Qwen 2.5-Max API is now available through Alibaba Cloud under the model name “qwen-max-2025-01-25”. Interested users can get started by registering an Alibaba Cloud account, activating the Model Studio service, and generating an API key.

The API is even compatible with OpenAI’s ecosystem, making integration straightforward for existing projects and workflows. This compatibility lowers the barrier for those eager to test their applications with the model’s capabilities.

Alibaba has made a strong statement of intent with Qwen 2.5-Max. The company’s ongoing commitment to scaling AI models is not just about improving performance benchmarks but also about enhancing the fundamental thinking and reasoning abilities of these systems.

“The scaling of data and model size not only showcases advancements in model intelligence but also reflects our unwavering commitment to pioneering research,” Alibaba noted.

Looking ahead, the team aims to push the boundaries of reinforcement learning to foster even more advanced reasoning skills. This, they say, could enable their models to not only match but surpass human intelligence in solving intricate problems.

The implications for the industry could be profound. As scaling methods improve and Qwen models break new ground, we are likely to see further ripples across AI-driven fields globally that we’ve seen in recent weeks.

(Photo by Maico Amorim)

See also: ChatGPT Gov aims to modernise US government agencies

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here."
What’s next for smart glasses,https://www.technologyreview.com/2025/02/05/1110983/whats-next-for-smart-glasses/,2025-02-05 00:00:00,"Now the general public may finally be getting access to devices they can use. The AI world is abuzz over agents, which augment large language models (LLMs) with the ability to carry out tasks by themselves. The past 12 months have seen huge leaps in AI multimodal LLMs’ abilities to handle video, images, and audio in addition to text, which opens up new applications for smart glasses that would not have been possible previously, says Louis Rosenberg, an AR researcher who worked on the first functional augmented-reality system at Stanford University in the 1990s.

We already know Meta is definitely interested in AI agents. Although the company said in September that it has no plans to sell its Orion prototype glasses to the public, given their expense, Mark Zuckerberg raised expectations for its next generations of Meta’s smart glasses when he declared Orion the “most advanced pair of AR glasses ever made.” He’s also made it clear how deeply invested Meta is in bringing a “highly intelligent and personalized AI assistant” to as many users as possible and that he’s confident Meta’s glasses are the “perfect form factor for AI.”

Although Meta is already making its Ray-Ban smart glasses’ AI more conversational—its new live AI feature responds to prompts about what its wearer is seeing and hearing via its camera and microphone—future agents will give these systems not only eyes and ears, but a contextual awareness of what’s around them, Rosenberg says. For example, agents running on smart glasses could hold unprompted interactive conversations with their wearers based on their environment, reminding them to buy orange juice when they walk past a store, for example, or telling them the name of a coworker who passes them on the sidewalk. We already know Google is deeply interested in this agent-first approach: The unnamed smart glasses it first showed off at Google I/O in May 2024 were powered by its Astra AI agent system.

“Having worked on mixed reality for over 30 years, it’s the first time I can see an application that will really drive mass adoption,” Rosenberg says.

Meta and Google will likely tussle to be the sector’s top dog

It’s unclear how far we are from that level of mass adoption. During a recent Meta earnings call, Zuckerberg said 2025 would be a “defining year” for understanding the future of AI glasses and whether they explode in popularity or represent “a longer grind.”"
Four Chinese AI startups to watch beyond DeepSeek,https://www.technologyreview.com/2025/02/04/1110942/four-chinese-ai-startups-deepseek/,2025-02-04 00:00:00,"An elite group of companies known as the “Six Tigers”—Stepfun, Zhipu, Minimax, Moonshot, 01.AI, and Baichuan—are generally considered to be at the forefront of China’s AI sector. But alongside them, research-focused firms like DeepSeek and ModelBest continue to grow in influence. Some, such as Minimax and Moonshot, are giving up on costly foundational model training to hone in on building consumer-facing applications on top of others’ models. Others, like Stepfun and Infinigence AI, are doubling down on research, driven in part by US semiconductor restrictions.

We have identified these four Chinese AI companies as the ones to watch.

Stepfun

Founded in April 2023 by former Microsoft senior vice president Jiang Daxin, Stepfun emerged relatively late onto the AI startup scene, but it has quickly become a contender thanks to its portfolio of foundational models. It is also committed to building artificial general intelligence (AGI), a mission a lot of Chinese startups have given up on.

With backing from investors like Tencent and funding from Shanghai’s government, the firm released 11 foundational AI models last year—spanning language, visual, video, audio, and multimodal systems. Its biggest language model so far, Step-2, has over 1 trillion parameters (GPT-4 has about 1.8 trillion). It is currently ranked behind only ChatGPT, DeepSeek, Claude, and Gemini’s models on LiveBench, a third-party benchmark site that evaluates the capabilities of large language models."
OpenAI’s new agent can compile detailed reports on practically any topic,https://www.technologyreview.com/2025/02/03/1110826/openais-new-agent-can-compile-detailed-reports-on-practically-any-topic/,2025-02-03 00:00:00,"OpenAI claims the tool represents a significant step toward its overarching goal of developing artificial general intelligence (AGI) that matches (or surpasses) human performance. It says that what takes the tool “tens of minutes” would take a human many hours.

In response to a single query, such as “Draw me up a competitive analysis between streaming platforms,” Deep Research will search the web, analyze the information it encounters, and compile a detailed report that cites its sources. It’s also able to draw from files uploaded by users.

OpenAI developed Deep Research using the same “chain of thought” reinforcement-learning methods it used to create its o1 multistep reasoning model. But while o1 was designed to focus primarily on mathematics, coding, or other STEM-based tasks, Deep Research can tackle a far broader range of subjects. It can also adjust its responses in reaction to new data it comes across in the course of its research.



This doesn’t mean that Deep Research is immune from the pitfalls that befall other AI models. OpenAI says the agent can sometimes hallucinate facts and present its users with incorrect information, albeit at a “notably” lower rate than ChatGPT. And because each question may take between five and 30 minutes for Deep Research to answer, it’s very compute intensive—the longer it takes to research a query, the more computing power required.

Despite that, Deep Research is now available at no extra cost to subscribers to OpenAI’s paid Pro tier and will soon roll out to its Plus, Team, and Enterprise users."
DeepSeek might not be such good news for energy after all,https://www.technologyreview.com/2025/01/31/1110776/deepseek-might-not-be-such-good-news-for-energy-after-all/,2025-01-31 00:00:00,"Add the fact that other tech firms, inspired by DeepSeek’s approach, may now start building their own similar low-cost reasoning models, and the outlook for energy consumption is already looking a lot less rosy.

The life cycle of any AI model has two phases: training and inference. Training is the often months-long process in which the model learns from data. The model is then ready for inference, which happens each time anyone in the world asks it something. Both usually take place in data centers, where they require lots of energy to run chips and cool servers.

On the training side for its R1 model, DeepSeek’s team improved what’s called a “mixture of experts” technique, in which only a portion of a model’s billions of parameters—the “knobs” a model uses to form better answers—are turned on at a given time during training. More notably, they improved reinforcement learning, where a model’s outputs are scored and then used to make it better. This is often done by human annotators, but the DeepSeek team got good at automating it.

The introduction of a way to make training more efficient might suggest that AI companies will use less energy to bring their AI models to a certain standard. That’s not really how it works, though.

“⁠Because the value of having a more intelligent system is so high,” wrote Anthropic cofounder Dario Amodei on his blog, it “causes companies to spend more, not less, on training models.” If companies get more for their money, they will find it worthwhile to spend more, and therefore use more energy. “The gains in cost efficiency end up entirely devoted to training smarter models, limited only by the company’s financial resources,” he wrote. It’s an example of what’s known as the Jevons paradox.

But that’s been true on the training side as long as the AI race has been going. The energy required for inference is where things get more interesting.

DeepSeek is designed as a reasoning model, which means it’s meant to perform well on things like logic, pattern-finding, math, and other tasks that typical generative AI models struggle with. Reasoning models do this using something called “chain of thought.” It allows the AI model to break its task into parts and work through them in a logical order before coming to its conclusion.

You can see this with DeepSeek. Ask whether it’s okay to lie to protect someone’s feelings, and the model first tackles the question with utilitarianism, weighing the immediate good against the potential future harm. It then considers Kantian ethics, which propose that you should act according to maxims that could be universal laws. It considers these and other nuances before sharing its conclusion. (It finds that lying is “generally acceptable in situations where kindness and prevention of harm are paramount, yet nuanced with no universal solution,” if you’re curious.)"
How the Rubin Observatory will help us understand dark matter and dark energy,https://www.technologyreview.com/2025/02/04/1110927/how-the-rubin-observatory-will-help-us-understand-dark-matter-and-dark-energy/,2025-02-04 00:00:00,"Other observatories, like the Hubble Space Telescope and the James Webb Space Telescope, have already begun stitching together this map from their images of galaxies. But Rubin plans to do so with exceptional precision and scale, analyzing the shapes of billions of galaxies rather than the hundreds of millions that current telescopes observe, according to Andrés Alejandro Plazas Malagón, Rubin operations scientist at SLAC National Laboratory. “We’re going to have the widest galaxy survey so far,” Plazas Malagón says.

Capturing the cosmos in such high definition requires Rubin’s 3.2-billion-pixel Large Synoptic Survey Telescope (LSST). The LSST boasts the largest focal plane ever built for astronomy, granting it access to large patches of the sky.

The telescope is also designed to reorient its gaze every 34 seconds, meaning astronomers will be able to scan the entire sky every three nights. The LSST will revisit each galaxy about 800 times throughout its tenure, says Steven Ritz, a Rubin project scientist at the University of California, Santa Cruz. The repeat exposures will let Rubin team members more precisely measure how the galaxies are distorted, refining their map of dark matter’s web. “We’re going to see these galaxies deeply and frequently,” Ritz says. “That’s the power of Rubin: the sheer grasp of being able to see the universe in detail and on repeat.”

The ultimate goal is to overlay this map on different models of dark matter and examine the results. The leading idea, the cold dark matter model, suggests that dark matter moves slowly compared to the speed of light and interacts with ordinary matter only through gravity. Other models suggest different behavior. Each comes with its own picture of how dark matter should clump in halos surrounding galaxies. By plotting its chart of dark matter against what those models predict, Rubin might exclude some theories and favor others.

A cosmic tug of war

If dark matter lies on one side of a magnet, pulling matter together, then you’ll flip it over to find dark energy, pushing it apart. “You can think of it as a cosmic tug of war,” Plazas Malagón says.

Dark energy was discovered in the late 1990s, when astronomers found that the universe was not only expanding, but doing so at an accelerating rate, with galaxies moving away from one another at higher and higher speeds."
European AI startups raised $8 billion in 2024,https://techcrunch.com/2025/02/04/european-ai-startups-raised-8-billion-in-2024/,2025-02-04 00:00:00,"In just a few days, France will host the Artificial Intelligence Action Summit, with heads of state flocking to Paris to meet global tech leaders. They’ll most likely announce some big investments and diplomatic agreements focused on safety or the environmental impact of artificial intelligence.

Ahead of the summit, early-stage VC firm Galion.exe, growth investment firm Revaia, and advisory firm Chausson Partners teamed up to create the French AI Report, which looks at the current trends in the tech ecosystem.

While all eyes are currently on the U.S. and China with OpenAI looking to raise tens of billions of dollars and DeepSeek capturing everyone’s attention, there has been a boom in AI startups in Europe, too. In 2024 alone, AI companies represented around 20% of all VC funding in the region.

In total, that represents around $8 billion in funding for AI startups in 2024. That metric is most likely going to grow rapidly, as AI startups are still relatively young. Seventy percent of the capital raised by AI startups in 2024 was for a seed to Series B round.

European countries that tend to attract VC funding in general have also become the main AI investment hubs, with the U.K. leading the group, France and Germany following suit, and the Nordics punching above its demographic weight. Here’s the breakdown from 2020 to 2024:

Interestingly, as AI companies become bigger, they tend to attract international investors, with U.S. VC firms accounting for around 50% of money invested in AI companies at the Series C round and later.

In France more specifically, there are “more than 750 startups that have created 35,000 jobs and operate in all areas that are transforming today’s society,” Minister Delegate for artificial intelligence and digital technologies Clara Chappaz said at a press conference.

She also mentioned that there are 2,000 scientists focused on AI research and 600 doctorate students working on artificial intelligence. And you may have noticed that there are quite a few French engineers and researchers working for AI companies in the U.S., too.

The team behind the French AI Report looked more closely at the top 400 AI startups in France and tried to identify the rising stars. While Mistral AI and Poolside are already some familiar names for readers who have followed the AI industry, the vast majority of AI startups aren’t working on the next foundation model.

On the infrastructure front, some companies are optimizing the data workflows and pipelines, such as Linkup and Kestra, or improving inference performance, such as ZML, or developing agents that can sift through large data sets and improve productivity. Dust is a good example of that.

But the reality is that most AI startups in France are focusing on applications for specific verticals. Based on this report, two important areas for AI startups in France are health and climate.

Owkin and its spin-off biotech company Bioptimus have been leading the pack on the health tech front, but it’s a surprisingly diverse group of companies with three big areas of interest: imaging tools, drug discovery, and medical treatment improvement.

Similarly, while a large chunk of the AI industry is focused on productivity gains for office workers, artificial intelligence is also actively being used to build the next-generation of climate startups. In addition to agritech, carbon and energy management — two topics that are related — seem to be a big focus. There are also a handful of promising new materials companies that are emerging (Altrove, for instance).

All the companies included in the list can be found here. You’ll also find plenty of AI companies working on one job function — sales, customer care, HR or legal — and using AI to simplify the most common tasks.

Of course, some companies aren’t going to be there in five years. But many of them are currently growing at a rapid pace. We’re still at the beginning of the AI revolution, and though it’s easy to think about the AI industry as a zero-sum game with one country or one company “winning” over the others, it seems like the AI boom is more distributed than expected."
Google wants Search to be more like an AI assistant in 2025,https://techcrunch.com/2025/02/04/google-wants-search-to-be-more-like-an-ai-assistant-in-2025/,2025-02-04 00:00:00,"Google Search is in the midst of a “journey” around AI, Google CEO Sundar Pichai said during the company’s earnings call on Tuesday. The start of that journey was AI overviews, a controversial and monumental shift in how Google delivers information to billions of Search users.

But that was just the beginning.

“As AI continues to expand the universe of queries that people can ask, 2025 is going to be one of the biggest years for search innovation yet,” said Pichai during his opening remarks on the call.

Throughout the call, Pichai laid out the next phase of Google’s plan to pack Search with AI features from the company’s research lab, DeepMind. The Search product is slowly becoming more like an AI assistant that browses the internet for you, looks at web pages, and returns an answer.

It’s a long way off from a simple search system that gives you ten blue links.

Google has been on this path for a few years now, ever since the search giant was caught flat footed by the release of OpenAI’s ChatGPT in 2022. The shift has massive implications for websites that rely on Google’s traffic and businesses that buy ads on Google Search.

Not everyone is happy about it, but Google is pushing ahead.

When asked about the future of AI and Search, Pichai said that, “You can imagine the future with Project Astra,” a reference to DeepMind’s multimodal AI system, which can process live video from a camera or computer screen and answer user questions about what the AI sees in real time.

Google has big plans for Project Astra in other parts of its business too. The company says it wants the multimodal AI system to power a pair of augmented reality smart glasses one day, which Google will create the operating system for.

Pichai also mentioned Gemini Deep Research – an AI agent that takes several minutes to create long research reports – as a feature that could fundamentally shift how people use Google Search. Deep Research automates work that people have traditionally done with Google Search. But now, it seems Google wants to do that research for users.

“You are really dramatically expanding the types of use cases for which Search can work – things which don’t always get answered instantaneously, but can take some time to answer,” said Pichai. “Those are all areas of exploration, and you will see us putting new experiences in front of users through the course of 2025.”

Pichai said further that Google has a “clear sense” of the Search experiences it could create with another one of Google’s AI agents, Project Mariner. That system can use the front-end of websites on behalf of users, making it unnecessary for people to use websites themselves.

Google’s CEO also said there’s an “opportunity” around letting users interact more and ask follow-up questions with Google Search. Pichai was light on details there, but it sounds like Google is considering ways to make its Search interface more like a chatbot.

“I think the [Search] product will evolve even more,” said Pichai. “As you make it more easy for people to interact and ask follow-up questions, etc., I think we have an opportunity to drive further growth.”

Today, ChatGPT has matured into one of the internet’s most used products, with hundreds of millions of weekly users. It presents an existential threat to Google Search’s long-term business. To address it, Google is not only building a competitor AI chatbot with Gemini, but also injecting AI features directly in Search.

Of course, the first step on Google Search’s AI journey did not go very well. When Google rolled out AI overviews to all of Google Search, the system displayed inaccurate and weird AI hallucinations. These included answers that told people to eat rocks and put glue on their pizza. Google admitted at the time that AI overviews needed some work.

Despite this negative rollout, it appears Google is just getting started putting AI into Search."
"Alphabet praises DeepSeek, but it’s massively ramping up its AI spending",https://techcrunch.com/2025/02/04/alphabet-praises-deepseek-but-its-massively-ramping-up-its-ai-spending/,2025-02-04 00:00:00,"Booming AI budgets seemed at risk last week when DeepSeek crashed Nvidia’s stock based on speculation that its cheaper AI models would lower demand for AI chips and data centers.

Alphabet CEO Sundar Pichai has certainly noticed the Chinese AI company, praising its work as “tremendous” in Alphabet’s latest earnings call (while adding that some of Gemini’s models are just as efficient).

But just like Meta, Alphabet isn’t throwing down the towel in Big Tech’s AI spending wars. In its latest earnings report, Alphabet announced it would boost capital expenditures to $75 billion this year — a whopping 42% increase — to accelerate its AI progress.

Alphabet is betting that cheaper AI will massively boost demand for its services, rather than making it basically free and threatening its business models. The company noted it stands to benefit from this rise in usage — known as inference — thanks to its billions of existing users.

“Part of the reason we are so excited about the AI opportunity is we know we can drive extraordinary use cases because the cost of actually using it is going to keep coming down, which will make more use cases feasible,” Pichai said during the earnings call. “And that’s the opportunity space. It’s as big as it comes, and that’s why you’re seeing us invest to meet that moment.”

Meta CEO Mark Zuckerberg made similar comments in Meta’s earnings call last week, pledging to spend “hundreds of billions” on AI in the long term despite all the DeepSeek buzz.

Whether this all pans out is unclear, but for now, tech giants can afford the AI bills, and when (or if) they’ll slow down is anyone’s guess."
AMD pulls up the release of its next-gen data center GPUs,https://techcrunch.com/2025/02/04/amd-pulls-up-the-release-of-its-next-gen-data-center-gpus/,2025-02-04 00:00:00,"AMD says that it plans to launch its next major data center GPUs, the AMD Instinct MI350 series, sooner than originally announced.

During the company’s Q4 2024 earnings call Tuesday, AMD CEO Lisa Su said AMD plans to sample the MI350 with “lead customers” this quarter and “accelerate” production shipments to “mid-year.”

“So, we had previously stated that we thought we would launch [the MI350] in the second half of [2025],” Su said. “And frankly, that bring-up has come up better than we expected, and there’s very strong customer demand, so we are actually going to pull that production ramp into the middle of the year, which improves our relative competitiveness.”

AMD’s data center revenue pales in comparison to rival Nvidia’s, which regularly eclipses tens of billions of dollars per quarter. But AMD has gained ground in the last year, acquiring and retaining customers, including Meta, Microsoft, and IBM.

AMD says that sales of AMD Instinct chips reached over $5 billion in 2024, and the company expects its data center segment to grow “double digits” in 2025. Last year, data center revenue made up around half ($3.9 billion) of AMD’s overall revenue ($7.1 billion), the company reported on Tuesday.

“I believe that the demand for AI compute is strong,” Su continued. “[MI350] will be a catalyst for the data center GPU business … We see [the data center] business growing to tens of billions as we go through the next couple of years.”

Investors seemed generally pleased with AMD’s fourth-quarter results. The company’s stock was up 4.58% as of publish time."
Google removes pledge to not use AI for weapons from website,https://techcrunch.com/2025/02/04/google-removes-pledge-to-not-use-ai-for-weapons-from-website/,2025-02-04 00:00:00,"In Brief

Google removed a pledge to not build AI for weapons or surveillance from its website this week. The change was first spotted by Bloomberg. The company appears to have updated its public AI principles page, erasing a section titled “applications we will not pursue,” which was still included as recently as last week.

Asked for comment, the company pointed TechCrunch to a new blog post on “responsible AI.” It notes, in part, “we believe that companies, governments, and organizations sharing these values should work together to create AI that protects people, promotes global growth, and supports national security.”

Google’s newly updated AI principles note the company will work to “mitigate unintended or harmful outcomes and avoid unfair bias,” as well as align the company with “widely accepted principles of international law and human rights.”

In recent years, Google’s contracts to provide the U.S. and Israeli militaries with cloud services have sparked internal protests from employees. The company has maintained that its AI is not used to harm humans; however, the Pentagon’s AI chief recently told TechCrunch that some company’s AI models are speeding up the U.S. military’s kill chain."
