title,link,publish_date,content,FINAL,SCORE
"Yiannis Antoniou, Lab49: OpenAI Operator kickstarts era of browser AI agents",https://www.artificialintelligence-news.com/news/yiannis-antoniou-lab49-openai-operator-era-browser-ai-agents/,2025-01-24 14:03:14+00:00,"Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry), Bluesky (@gadgetry.bsky.social), and/or Mastodon (@gadgetry@techhub.social)

OpenAI has unveiled Operator, a tool that integrates seamlessly with web browsers to perform tasks autonomously. From filling out forms to ordering groceries, Operator promises to simplify repetitive online activities by interacting directly with websites through clicks, typing, and scrolling.

Designed around a new model called the Computer-Using Agent (CUA), Operator combines GPT-4o’s vision recognition with advanced reasoning capabilities—allowing it to function as a virtual “human-in-the-browser.” Yet, for all its innovation, industry experts see room for refinement.

Yiannis Antoniou, Head of AI, Data, and Analytics at specialist consultancy Lab49, shared his insights on Operator’s significance and positioning in the competitive landscape of agent AI systems.

Agentic AI through a familiar interface

“OpenAI’s announcement of Operator, its latest foray into the agentic AI wars, is both fascinating and incomplete,” said Antoniou, who has over two decades of experience designing AI systems for financial services firms.

“Clearly influenced by Anthropic Claude’s Computer Use system, introduced back in October, Operator streamlines the experience by removing the need for complex infrastructure and focusing on a familiar interface: the browser.”

By designing Operator to operate within an environment users already understand, the web browser, OpenAI sidesteps the need for bespoke APIs or integrations.

“By leveraging the world’s most popular interface, OpenAI enhances the user experience and captures immediate interest from the general public. This browser-centric approach creates significant potential for widespread adoption, something Anthropic – despite its early-mover advantage – has struggled to achieve.”

Unlike some competing systems that may feel technical or niche in their application, Operator’s browser-focused framework lowers the barrier to entry and is a step forward in OpenAI’s efforts to democratise AI.

Unique take on usability and security

One of the hallmarks of Operator is its emphasis on adaptability and security, implemented through human-in-the-loop protocols. Antoniou acknowledged these thoughtful usability features but noted that more work is needed.

“Architecturally, Operator’s browser integration closely mirrors Claude’s system. Both involve taking screenshots of the user’s browser and sending them for analysis, as well as controlling the screen via virtual keystrokes and mouse movements. However, Operator introduces thoughtful usability touches.

“Features like custom instructions for specific websites add a layer of personalisation, and the emphasis on human-in-the-loop safeguards against unauthorised actions – such as purchases, sending emails, or applying for jobs – demonstrate OpenAI’s awareness of potential security risks posed by malicious websites, but more work is clearly needed to make this system widely safe across a variety of scenarios.”

OpenAI has implemented a multi-layered safety framework for Operator, including takeover mode for secure inputs, user confirmations prior to significant actions, and monitoring systems to detect adversarial behavior. Furthermore, users can delete browsing data and manage privacy settings directly within the tool.

However, Antoniou emphasised that these measures are still evolving—particularly as Operator encounters complex or sensitive tasks.

OpenAI Operator further democratises AI

Antoniou also sees the release of Operator as a pivotal moment for the consumer AI landscape, albeit one that is still in its early stages.

“Overall, this is an excellent first attempt at building an agentic system for everyday users, designed around how they naturally interact with technology. As the system develops – with added capabilities and more robust security controls – this limited rollout, priced at $200/month, will serve as a testing ground.

“Once matured and extended to lower subscription tiers and the free version, Operator has the potential to usher in the era of consumer-facing agents, further democratising AI and embedding it into daily life.”

Designed initially for Pro users at a premium price point, Operator provides OpenAI with an opportunity to learn from early adopters and refine its capabilities.

Antoniou noted that while $200/month might not yet justify the system’s value for most users, investment in making Operator more powerful and accessible could lead to significant competitive advantages for OpenAI in the long run.

“Is it worth $200/month? Perhaps not yet. But as the system evolves, OpenAI’s moat will grow, making it harder for competitors to catch up. Now, the challenge shifts back to Anthropic and Google – both of whom have demonstrated similar capabilities in niche or engineering-focused products – to respond and stay in the game,” he concludes.

As OpenAI continues to fine-tune Operator, the potential to revolutionise how people interact with technology becomes apparent. From collaborations with companies like Instacart, DoorDash, and Uber to use cases in the public sector, Operator aims to balance innovation with trust and safety.

While early limitations and pricing may deter widespread adoption for now, these hurdles might only be temporary as OpenAI commits to enhancing usability and accessibility over time.

See also: OpenAI argues against ChatGPT data deletion in Indian court

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here.","**Operator: Your Browser's New Best Friend - Even If You're Not Techy**

**Why Read This?**

OpenAI just launched ""Operator,"" a clever tool that lives right inside your web browser and does things for you! Think of it as a super-powered helper that can fill out forms, order groceries, and do all those annoying online tasks you hate.

**Why It Matters for You:**

Imagine having a virtual assistant that knows how to click, type, and scroll just like you do. Operator uses smart AI to understand websites and do things for you automatically. It’s like having a magic button for online chores. While it's still in its early stages, it's a glimpse into a future where AI handles the boring parts of the internet for you. Experts are already excited about how this could change the way we use technology, making it simpler and more accessible for everyone. 

**Want More?**

Explore the full details here: https://www.artificialintelligence-news.com/news/yiannis-antoniou-lab49-openai-operator-era-browser-ai-agents/
","7
"
How AI helped refine Hungarian accents in The Brutalist,https://www.artificialintelligence-news.com/news/how-ai-helped-refine-hungarian-accents-in-the-brutalist/,2025-01-24 13:38:07+00:00,"As a tech journalist, Zul focuses on topics including cloud computing, cybersecurity, and disruptive technology in the enterprise industry. He has expertise in moderating webinars and presenting content on video, in addition to having a background in networking technology.

When it comes to movies buzzing with Oscar potential, Brady Corbet’s The Brutalist is a standout this awards season.

The visually stunning drama transports viewers to the post-World War II era, unravelling the story of László Tóth, played by Adrien Brody. Tóth, a fictional Hungarian-Jewish architect, starts over in the United States after being forced to leave his family behind as he emigrates.

Beyond its vintage allure, something modern brews in the background: the use of AI. Specifically, AI was employed to refine Brody’s and co-star Felicity Jones’ Hungarian pronunciation. The decision has sparked lively debates about technology’s role in film-making.

The role of AI in The Brutalist

According to Dávid Jancsó, the film’s editor, the production team turned to Respeecher, an AI software developed by a Ukrainian company, to tweak the actors’ Hungarian dialogue. Speaking to RedShark News (as cited by Mashable SEA), Jancsó explained that Hungarian – a Uralic language known for its challenging sounds – was a significant hurdle for the actors, despite their talent and dedication.

Respeecher’s software isn’t magic, but just a few years ago, it would have seemed wondrous. It creates a voice model based on a speaker’s characteristics and adjusts specific elements, like pronunciation. In this case, it was used to fine-tune the letter and vowel sounds that Brody and Jones found tricky. Most of the corrections were minimal, with Jancsó himself providing some replacement sounds to preserve the authenticity of the performances. “Most of their Hungarian dialogue has a part of me talking in there,” he joked, emphasising the care taken to maintain the actors’ original delivery.

Respeecher: AI behind the scenes

The is not Respeecher’s first foray into Hollywood. The software is known for restoring iconic voices like that of Darth Vader for the Obi-Wan Kenobi series, and has recreated Edith Piaf’s voice for an upcoming biopic. Outside of film, Respeecher has helped to preserve endangered languages like Crimean Tatar.

For The Brutalist, the AI tool wasn’t just a luxury – it was a time and budget saver. With so much dialogue in Hungarian, manually editing every line would have required painstaking, manual work. Jancsó said that using AI sped up the process significantly, an important factor given the film’s modest $10 million budget.

Beyond voice: AI’s other roles in the film

AI was also used in other aspects of the production process, used for example to generate some of Tóth’s architectural drawings and complete buildings in the film’s Venice Biennale sequence. However, director Corbet has clarified that these images were not fully AI-generated; instead, the AI was used for specific background elements.

Corbet and Jancsó have been candid about their perspectives on AI in film-making. Jancsó sees it as a valuable tool, saying, “There’s nothing in the film using AI that hasn’t been done before. It just makes the process a lot faster.” Corbet added that the software’s purpose was to enhance authenticity, not replace the actors’ hard work.

A broader conversation

The debate surrounding AI in the film industry isn’t new. From script-writing to music production, concerns about generative AI’s impact were central to the 2023 Writers Guild of America (WGA) and SAG-AFTRA strikes. Although agreements have been reached to regulate the use of AI, the topic remains a hot-button issue.

The Brutalist awaits a possible Oscar nomination. From its story line to its cinematic style, the film wears its ambition on its sleeve. It’s not just a celebration of the postwar Brutalist architectural movement, it’s also a nod to classic American cinema. Shot in the rarely used VistaVision format, the film captures the grandeur of mid-20th-century film-making. Adding to its nostalgic charm, it includes a 15-minute intermission during its epic three-and-a-half-hour runtime.

Yet the use of AI has given a new dimension to the ongoing conversation about AI in the creative industry. Whether people see AI as a betrayal of craftsmanship or an exciting innovative tool that can add to a final creation, one thing is certain: AI continues to transform how stories are delivered on screen.

See also: AI music sparks new copyright battle in US courts

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here.","**The Brutalist: When Hollywood Met AI (And It Wasn't a Sci-Fi Movie)**

**Why Read This?**

Get ready for some Oscar buzz! ""The Brutalist,"" a new movie about a post-WWII architect, is making waves – and not just for its story. This film used AI to tweak the actors' Hungarian accents, sparking a whole debate about technology in movies.

**Why It Matters for You:**

Imagine trying to learn a language with tricky sounds. That's what the actors in ""The Brutalist"" faced! To help them nail their Hungarian pronunciation, the filmmakers used AI. It’s like having a super tutor that can fine-tune specific sounds, making the performances more authentic. This isn’t about replacing actors; it’s about enhancing their work. This shows how AI is making its way into creative fields, changing how movies are made, and raising questions about how we use tech in art.

**Want More?**

Explore the full details here: https://www.artificialintelligence-news.com/news/how-ai-helped-refine-hungarian-accents-in-the-brutalist/
","8
"
OpenAI targets business sector with advanced AI tools,https://www.artificialintelligence-news.com/news/openai-targets-business-sector-advanced-ai-tools/,2025-01-24 13:30:53+00:00,"OpenAI, the powerhouse behind ChatGPT, is ramping up efforts to dominate the enterprise market with a suite of AI tools tailored for business users.

The company recently revealed its plans to introduce a series of enhancements designed to make AI integration seamless for companies of all sizes. This includes updates to its flagship AI agent technology, expected to transform workplace productivity by automating complex workflows, from financial analysis to customer service.

“Businesses are looking for solutions that go beyond surface-level assistance. Our agents are designed to provide in-depth, actionable insights,” said Sarah Friar, CFO of OpenAI. “This is particularly relevant as enterprises seek to streamline operations in today’s competitive landscape.”

OpenAI’s corporate strategy builds on its ongoing collaborations with tech leaders such as Microsoft, which has already integrated OpenAI’s technology into its Azure cloud platform. Analysts say these partnerships position OpenAI to rival established enterprise solutions providers like Salesforce and Oracle.

AI research assistant tools

As part of its enterprise-focused initiatives, OpenAI is emphasising the development of AI research tools that cater to specific industries.

For instance, its AI models are being trained on legal and medical data to create highly specialised assistants that could redefine research-intensive sectors. This focus aligns with the broader market demand for AI-driven solutions that enhance decision-making and efficiency.

Infrastructure for expansion

OpenAI’s rapid growth strategy is supported by a robust infrastructure push. The company has committed to building state-of-the-art data centers in Europe and Asia, aiming to lower latency and improve service reliability for global users. These investments reflect OpenAI’s long-term vision of becoming a critical enabler in the AI-driven global economy.

Challenges and issues

However, challenges persist. The company faces mounting pressure from regulators concerned about data privacy and the ethical implications of deploying powerful AI tools. Critics also question the sustainability of OpenAI’s ambitious growth targets, given its significant operational costs and strong competition from other tech giants.

Despite these hurdles, OpenAI remains optimistic about its trajectory. With plans to unveil its expanded portfolio at the upcoming Global AI Summit, the company is well-positioned to strengthen its foothold in the burgeoning AI enterprise market.

(Editor’s note: This article is sponsored by AI Tools Network)

See also: OpenAI argues against ChatGPT data deletion in Indian court

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here.","**ChatGPT for Work? OpenAI's Big Plans to Change Business**

**Why Read This?**

The makers of ChatGPT, OpenAI, aren't just about chatbots anymore. They're diving headfirst into the business world, creating AI tools that could transform how companies operate. Think smarter software and automated tasks!

**Why It Matters for You:**

Imagine if AI could handle all the tedious parts of your job, from crunching numbers to answering customer questions. That's what OpenAI is aiming for. They're building AI tools that can do more than just provide simple answers; they can offer real insights and help businesses make better decisions. This could mean more efficient workplaces, faster processes, and maybe even fewer boring tasks for you. While there are questions about privacy and the impact of AI, it's clear that this tech is poised to reshape the future of work.

**Want More?**

Explore the full details here: https://www.artificialintelligence-news.com/news/openai-targets-business-sector-advanced-ai-tools/
","6
"
OpenAI argues against ChatGPT data deletion in Indian court,https://www.artificialintelligence-news.com/news/openai-argues-against-chatgpt-data-deletion-in-indian-court/,2025-01-23 14:24:49+00:00,"As a tech journalist, Zul focuses on topics including cloud computing, cybersecurity, and disruptive technology in the enterprise industry. He has expertise in moderating webinars and presenting content on video, in addition to having a background in networking technology.

OpenAI has argued in an Indian court that removing the training data behind ChatGPT service would clash with its legal obligations in the United States.

The statement was issued in response to a lawsuit filed by Indian news agency ANI, which accused the AI business of using its content without permission.

The Microsoft-backed AI giant stated that Indian courts lack jurisdiction in the case since OpenAI has no offices nor operations in the country. In its January 10 filing to the Delhi High Court, OpenAI emphasised that it is already defending similar lawsuits in the US, where it is required to preserve its training data during ongoing litigation.

The case, filed by ANI in November, is one of India’s most closely-watched lawsuits involving the use of AI. ANI alleges that OpenAI utilised its published content without authorisation to train ChatGPT and is demanding the deletion of its data from the company’s systems.

A global battle over copyright and AI

OpenAI is no stranger to such disputes, facing a wave of lawsuits from copyright holders worldwide. In the US, the New York Times filed a similar case against the company, accusing it of misusing its content. OpenAI has consistently denied such allegations, claiming its systems rely on the fair use of publicly available data.

During a November hearing in Delhi, OpenAI told the court it would no longer use ANI’s content. However, ANI argued that its previously published material remains stored in ChatGPT’s repositories and must be deleted.

In its rebuttal, OpenAI highlighted that it is legally obligated under US law to retain training data while related cases are pending. “The company is under a legal obligation, under the laws of the United States, to preserve, and not delete, the said training data,” OpenAI stated in its filing.

Jurisdiction dispute

OpenAI also argued that the relief ANI is seeking falls outside the jurisdiction of Indian courts. It pointed out that the company has “no office or permanent establishment in India,” and its servers, which store ChatGPT’s training data, are located outside the country.

ANI, which is partially owned by Reuters, countered the claim, saying the Delhi court has the authority to hear the case and that it will file a detailed response.

A Reuters spokesperson declined to comment on proceedings, but has stated that the agency has no involvement in ANI’s business operations.

Concerns over competition

ANI has also expressed concern about unfair competition, citing OpenAI’s partnerships with major news organisations like Time Magazine, The Financial Times, and France’s Le Monde. ANI says that these agreements give OpenAI an edge.

The agency further claimed that ChatGPT reproduces verbatim or similar excerpts of its works in response to user prompts. OpenAI, on the other hand, claimed that ANI deliberately used its own articles as prompts to “manipulate ChatGPT” to file the lawsuit.

The case is scheduled to be heard by the Delhi High Court on January 28. Meanwhile, OpenAI is transitioning from a non-profit to a for-profit company, raising $6.6 billion last year.

In recent months, OpenAI has secured high-profile deals with media outlets from around the world, highlighting its efforts to strengthen its commercial partnerships while managing regulatory concerns worldwide.

(Photo by Unsplash)

See also: DeepSeek-R1 reasoning models rival OpenAI in performance

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here.","**ChatGPT's Data Drama: A Global Legal Fight You Should Know About**

**Why Read This?**

The company behind ChatGPT, OpenAI, is in a bit of a legal pickle. An Indian news agency is suing them, claiming they used its content without permission. This case is raising big questions about how AI learns and what's fair.

**Why It Matters for You:**

This isn't just a legal battle; it's about the future of AI. Imagine if every time you learned something new, you had to worry about whether you were using someone else’s knowledge without permission. That’s kind of what’s happening with ChatGPT. The news agency wants OpenAI to delete its data, but OpenAI says they can’t because they’re in another legal fight in the US. This case highlights a growing global debate about who owns data and how AI should use it. It's a messy situation with implications for anyone who uses AI tools.

**Want More?**

Explore the full details here: https://www.artificialintelligence-news.com/news/openai-argues-against-chatgpt-data-deletion-in-indian-court/
","7
"
World Economic Forum unveils blueprint for equitable AI,https://www.artificialintelligence-news.com/news/world-economic-forum-unveils-blueprint-equitable-ai/,2025-01-21 16:55:43+00:00,"Ryan Daws is a senior editor at TechForge Media with over a decade of experience in crafting compelling narratives and making complex topics accessible. His articles and interviews with industry leaders have earned him recognition as a key influencer by organisations like Onalytica. Under his leadership, publications have been praised by analyst firms such as Forrester for their excellence and performance. Connect with him on X (@gadget_ry), Bluesky (@gadgetry.bsky.social), and/or Mastodon (@gadgetry@techhub.social)

The World Economic Forum (WEF) has released a blueprint outlining how AI can drive inclusivity in global economic growth and societal progress. However, it also highlights the challenges in ensuring its benefits are equitably distributed across all nations and peoples.

Developed in partnership with KPMG, the blueprint offers nine strategic objectives to support government leaders, organisations, and key stakeholders through every phase of the AI lifecycle – from innovation to deployment – at local, national, and international levels. These strategies aim to bridge disparities in AI access, infrastructure, advanced computing, and skill development to promote sustainable, long-term growth.

Cathy Li, Head of AI, Data, and the Metaverse at the WEF, said: “Leveraging AI for economic growth and societal progress is a shared goal, yet countries and regions have very different starting points.

“This blueprint serves as a compass, guiding decision-makers toward impact-oriented collaboration and practical solutions that can unlock AI’s full potential.”

Call for regional collaboration and local empowerment

Central to the ‘Blueprint for Intelligent Economies’ is the belief that successful AI adoption must reflect the specific needs of local communities—with strong leadership and collaboration among governments, businesses, entrepreneurs, civil society organisations, and end users.

Solly Malatsi, South Africa’s Minister of Communications and Digital Technologies, commented: “The significant potential of AI remains largely untapped in many regions worldwide. Establishing an inclusive and competitive AI ecosystem will become a crucial priority for all nations.

“Collaboration among multiple stakeholders at the national, regional, and global levels will be essential in fostering growth and prosperity through AI for everyone.”

By tailoring approaches to reflect geographic and cultural nuances, the WEF report suggests nations can create AI systems that address local challenges while also providing a robust bedrock for innovation, investment, and ethical governance. Case studies from nations at varying stages of AI maturity are used throughout the report to illustrate practical, scalable solutions.

For example, cross-border cooperation on shared AI frameworks and pooled resources (such as energy or centralised databanks) is highlighted as a way to overcome resource constraints. Public-private subsidies to make AI-ready devices more affordable present another equitable way forward. These mechanisms aim to lower barriers for local businesses and innovators, enabling them to adopt AI tools and scale their operations.

Hatem Dowidar, Chief Executive Officer of E&, said: “All nations have a unique opportunity to advance their economic and societal progress through AI. This requires a collaborative approach of intentional leadership from governments supported by active engagement with all stakeholders at all stages of the AI journey.

“Regional and global collaborations remain fundamental pathways to address shared challenges and opportunities, ensure equitable access to key AI capabilities, and responsibly maximise its transformative potential for a lasting value for all.”

Priority focus areas

While the blueprint features nine strategic objectives, three have been singled out as priority focus areas for national AI strategies:

Building sustainable AI infrastructure

Resilient, scalable, and environmentally sustainable AI infrastructure is essential for innovation. However, achieving this vision will require substantial investment, energy, and cross-sector collaboration. Nations must coordinate efforts to ensure that intelligent economies grow in both an equitable and eco-friendly manner.

Curating diverse and high-quality datasets

AI’s potential hinges on the quality of the data it can access. This strategic objective addresses barriers such as data accessibility, imbalance, and ownership. By ensuring that datasets are inclusive, diverse, and reflective of local languages and cultures, developers can create equitable AI models that avoid bias and meet the needs of all communities.

Establishing robust ethical and safety guardrails

Governance frameworks are critical for reducing risks like misuse, bias, and ethical breaches. By setting high standards at the outset, nations can cultivate trust in AI systems, laying the groundwork for responsible deployment and innovation. These safeguards are especially vital for promoting human-centred AI that benefits all of society.

The overall framework outlined in the report has three layers:

Foundation layer: Focuses on sustainable energy, diverse data curation, responsible AI infrastructure, and efficient investment mechanisms. Growth layer: Embeds AI into workflows, processes, and devices to accelerate sectoral adoption and boost innovation. People layer: Prioritises workforce skills, empowerment, and ethical considerations, ensuring that AI shapes society in a beneficial and inclusive way.

A blueprint for global AI adoption

The Forum is also championing a multi-stakeholder approach to global AI adoption, blending public and private collaboration. Policymakers are being encouraged to implement supportive legislation and incentives to spark innovation and broaden AI’s reach. Examples include lifelong learning programmes to prepare workers for the AI-powered future and financial policies that enable greater technology access in underserved regions.

The WEF’s latest initiative reflects growing global recognition that AI will be a cornerstone of the future economy. However, it remains clear that the benefits of this transformative technology will need to be shared equitably to drive societal progress and ensure no one is left behind.

The Blueprint for Intelligent Economies provides a roadmap for nations to harness AI while addressing the structural barriers that could otherwise deepen existing inequalities. By fostering inclusivity, adopting robust governance, and placing communities at the heart of decision-making, the WEF aims to guide governments, businesses, and innovators toward a sustainable and intelligent future.

See also: UK Government signs off sweeping AI action plan

Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security & Cloud Expo.

Explore other upcoming enterprise technology events and webinars powered by TechForge here.","**AI for Everyone? The World Economic Forum's Plan for a Fair Future**

**Why Read This?**

The World Economic Forum (WEF) just dropped a big plan for how AI should grow in the world – and it's not just about tech. It's about making sure everyone, everywhere, gets a piece of the AI pie, not just the rich and powerful.

**Why It Matters for You:**

Imagine a world where AI helps solve problems in your community, no matter where you live. The WEF is trying to make that happen by ensuring AI tech, skills, and access reach every corner of the globe. It's not enough to just build cool AI; it has to be fair, ethical, and benefit everyone. This plan highlights the need to invest in sustainable tech, prioritize diverse data, and set ethical guidelines to prevent AI from creating more problems than it solves. It's a roadmap for a future where AI helps lift everyone up, not just a select few.

**Want More?**

Explore the full details here: https://www.artificialintelligence-news.com/news/world-economic-forum-unveils-blueprint-equitable-ai/
","7
"
Galileo launches Agentic Evaluations to fix AI agent errors before they cost you,https://venturebeat.com/ai/galileo-launches-agentic-evaluations-to-fix-ai-agent-errors-before-they-cost-you/,2025-01-23 13:00:00+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

Galileo, a San Francisco-based startup, is betting that the future of artificial intelligence depends on trust. Today, the company launched a new product, Agentic Evaluations, to address a growing challenge in the world of AI: making sure the increasingly complex systems known as AI agents actually work as intended.

AI agents — autonomous systems that perform multi-step tasks like generating reports or analyzing customer data — are gaining traction across industries. But their rapid adoption raises a crucial question: How can companies verify these systems remain reliable after deployment? Galileo’s CEO, Vikram Chatterji, believes his company has found the answer.

“Over the last six to eight months, we started to see some of our customers trying to adopt agentic systems,” said Chatterji in an interview. “Now LLMs can be used as a smart router to pick and choose the right API calls towards actually completing a task. Going from just generating text to actually completing a task was a very big chasm that was unlocked.”

A diagram showing how Galileo evaluates AI agents at three key stages: tool selection, error detection and task completion. (Credit: Galileo)

AI agents show promise, but enterprises demand accountability

Major enterprises like Cisco and Ema (the latter founded by Coinbase’s former chief product officer) have already adopted Galileo’s platform. These companies use AI agents to automate tasks from customer support to financial analysis, and report significant productivity gains.

“A sales representative who’s trying to do outreach and outbounds would otherwise use maybe a week of their time to do that, versus with some of these AI-enabled agents, they’re doing that within two days or less,” Chatterji explained, highlighting the return on investment for enterprises.

Galileo’s new framework evaluates tool selection quality, detects errors in tool calls, and tracks overall session success. It also monitors essential metrics for large-scale AI deployment, including costs and latency.

A dashboard showing how Galileo evaluates AI agents at three key stages: tool selection, error detection and task completion. (Credit: Galileo)

$68 million in funding fuels Galileo’s push into enterprise AI

The launch builds on Galileo’s recent momentum. The company raised $45 million in series B funding led by Scale Venture Partners last October, bringing its total funding to $68 million. Industry analysts project the market for AI operations tools could reach $4 billion by 2025.

The stakes are high as AI deployment accelerates. Studies show even advanced models like GPT-4 can hallucinate about 23% of the time during basic question-and-answer tasks. Galileo’s tools help enterprises identify these issues before they impact operations.

“Before we launch this thing, we really, really need to know that this thing works,” Chatterji said, describing customer concerns. “The bar is really high. So that’s where we gave them this tool chain, such that they could just use our metrics as the basis for these tests.”

Addressing AI hallucinations and enterprise-scale challenges

The company’s focus on reliable, production-ready solutions positions it well in a market increasingly concerned with AI safety. For technical leaders deploying enterprise AI, Galileo’s platform provides essential guardrails for ensuring AI agents perform as intended while controlling costs.

As enterprises expand their use of AI agents, performance monitoring tools become crucial infrastructure. Galileo’s latest offering aims to help businesses deploy AI responsibly and effectively at scale.

“2025 will be the year of agents. It is going to be very prolific,” Chatterji noted. “However, what we’ve also seen is a lot of companies that are just launching these agents without good testing is leading to negative implications…The need for proper testing and evaluations is more than ever before.”","**AI Agents Need a Check-Up? This Company Says Yes!**

**Why Read This?**

Ever wonder if those AI helpers are actually doing their job right? A startup called Galileo is tackling that question head-on. They've created a new tool to keep AI agents in check, making sure they're reliable before they cause chaos.

**Why It Matters for You:**

Imagine AI tools that can do tasks for you, like writing reports or helping customers, but sometimes they make mistakes. That's where Galileo comes in. They're basically giving AI agents a performance review, making sure they're selecting the right tools, avoiding errors, and completing tasks successfully. This is a big deal because as AI gets more complex, we need ways to ensure they're trustworthy and don't mess things up. It's like having a safety net for AI, helping businesses use these powerful tools with confidence.

**Want More?**

Explore the full details here: https://venturebeat.com/ai/galileo-launches-agentic-evaluations-to-fix-ai-agent-errors-before-they-cost-you/
","7
"
"Perplexity launches Sonar API, taking aim at Google and OpenAI with real-time AI search",https://venturebeat.com/ai/perplexity-launches-sonar-api-taking-aim-at-google-and-openai-with-real-time-ai-search/,2025-01-21 22:31:58+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

Perplexity has launched an aggressive bid to capture the enterprise AI search market, unveiling Sonar, an API service that outperforms offerings from Google, OpenAI and Anthropic on key benchmarks while also undercutting their prices.

The move signals a significant shift in the AI landscape, as Perplexity — now valued at $9 billion — directly challenges larger competitors by making its real-time, web-connected search capabilities available to developers and enterprises.

The company’s dual-tier strategy — offering both a lightweight Sonar service and a more robust Sonar Pro version — targets different segments of the growing AI integration market.

Perplexity’s Sonar Pro outperforms major AI competitors in the SimpleQA benchmark, which measures response accuracy. (Credit: Perplexity)



Sonar’s real-time advantage: Bringing fresh data to enterprises

Zoom has already integrated Sonar into its AI Companion 2.0 product, allowing users to access real-time information without leaving video conferences — a capability that could reshape how businesses conduct remote meetings and research.

The pricing structure appears to be designed to disrupt the market. Sonar’s base tier costs $5 per 1,000 searches plus minimal token fees, while Sonar Pro, despite higher token costs, offers doubled citation density and multi-search capabilities for complex queries.

What sets Sonar apart is its real-time web connection, a feature absent in many competing APIs that rely solely on training data. This approach could prove particularly valuable for enterprises requiring current information, although it may face challenges in applications requiring deterministic outputs.

Perplexity’s two-tier API offering shows the feature differences between Sonar Pro (left) and the base Sonar service (right), with Pro featuring enhanced citation capability and support for complex queries. (Credit: Perplexity)

Disruptive pricing: Affordable AI search for the enterprise market

The launch comes at a pivotal moment in the AI industry, when companies are increasingly seeking ways to integrate AI search capabilities into their products. With recent benchmarks showing Sonar Pro achieving an 85.8 F-score on the SimpleQA benchmark — significantly outperforming GPT-4o and Claude — Perplexity appears positioned to capitalize on growing enterprise demand for accurate, citation-backed AI responses.

The timing of this launch comes as Perplexity demonstrates significant market momentum, having just secured a $500 million funding round led by Institutional Venture Partners, which valued the company at $9 billion. This strategy could prove particularly effective as enterprises increasingly prioritize AI tools that provide verifiable, current information over black-box solutions.

For technical decision makers, Sonar’s launch represents a new option in the AI toolkit, particularly for applications requiring real-time information access and citation tracking. However, the true test will be whether Perplexity can maintain its performance edge and pricing advantage as larger competitors inevitably adjust their strategies.","**Forget Google? This AI Search Tool Is Coming for Your Business**

**Why Read This?**

A company called Perplexity is shaking up the AI world with a new search tool named Sonar. It's not just another search engine; it’s designed to be better than Google and even ChatGPT for businesses, and it might just change how companies access information.

**Why It Matters for You:**

Imagine having a search tool that gives you real-time, up-to-date answers, and can show you exactly where that information came from. That's what Sonar is offering. It's fast, accurate, and directly connected to the web, unlike many AI tools that use outdated data. This could transform how companies research, make decisions, and even conduct meetings. Perplexity is also undercutting the prices of big tech companies, making their powerful AI search more accessible. It's a potential game-changer for businesses who need reliable, current information.

**Want More?**

Explore the full details here: https://venturebeat.com/ai/perplexity-launches-sonar-api-taking-aim-at-google-and-openai-with-real-time-ai-search/
","8
"
OpenAI Stargate is a $500B bet: America’s AI Manhattan Project or costly dead end?,https://venturebeat.com/ai/openai-stargate-is-a-500b-bet-americas-ai-manhattan-project-or-costly-dead-end/,2025-01-22 16:38:00+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

In case you missed it amid the flurry of executive orders coming out of the White House in the days since President Trump returned to office for his second non-consecutive term this week, the single largest investment in AI infrastructure was just announced yesterday afternoon. Known as “the Stargate Project,” it’s a $500 billion (half a trillion) effort from OpenAI, SoftBank, Oracle and MGX to form a new venture that will build “new AI infrastructure for OpenAI in the United States,” and as OpenAI put it in its announcement post on the social network X, to “support the re-industrialization of the United States… also provide a strategic capability to protect the national security of America and its allies.”

The end goal: to build artificial general intelligence (AGI), or AI that outperforms humans on most economically valuable work, which has been OpenAI’s goal from the start — and ultimately, artificial superintelligence, or AI even smarter than humans can comprehend.

Flanked by Trump himself, OpenAI cofounder and CEO Sam Altman appeared at the White House alongside Softbank CEO Masayoshi “Masa” Son and Oracle executive chairman Larry Ellison, saying “I’m thrilled we get to do this in the United States of America. I think this will be the most important project of this era — and as Masa said, for AGI to get built here, to create hundreds of thousands of jobs, to create a new industry centered here — we wouldn’t be able to do this without you, Mr. President.”

Son called it “the beginning of our Golden Age.”

Several high-profile technology companies have partnered with the initiative to build and operate the infrastructure. Arm, Microsoft, Nvidia, Oracle and OpenAI are among the key partners contributing their expertise and resources to the effort. Oracle, Nvidia and OpenAI, in particular, will collaborate closely on developing the computing systems essential for the project’s success.

While some see the Stargate Project as a transformative investment in the future of AI, critics argue that it is a costly overreach, unnecessary in light of the rapid rise of leaner, open-source reasoning AI models like China’s DeepSeek R-1, which was just released earlier this week under a permissive MIT License — allowing it to be downloaded, fine-tuned or retrained, and used freely in commercial and noncommercial projects — and which matches or outperforms OpenAI’s own o1 reasoning models on key third-party benchmarks.

The debate has become a lightning rod for competing visions of AI development and the geopolitical dynamics shaping the race for technological supremacy.

A transformational leap forward?

For many advocates, the Stargate Project represents an unparalleled commitment to innovation and national competitiveness, on par with prior eras of large infrastructure spending such as the U.S. highway system during the Eisenhower era (though of course, that was with public funds — not private as in this case).

On X, AI commentator and former engineer David Shapiro said, “America just won geopolitics for the next 50 years with Project Stargate,” and likened the initiative to historic achievements like the Manhattan Project and NASA’s Apollo program.

He argued that this level of investment in artificial intelligence is not only necessary but inevitable, given the stakes. Shapiro described the project as a strategic move to ensure that America maintains technological supremacy, framing the investment as critical to solving global problems, driving economic growth and securing national security. “When America decides something matters and backs it with this kind of money? It happens. Period,” he declared.

In terms of practical applications, advocates point to the Stargate Project’s promise of AI-enabled breakthroughs in areas like cancer research, personalized medicine, and pandemic prevention.

Oracle’s Ellison has specifically highlighted the potential to develop new personalized mRNA-based vaccines and cancer treatments, revolutionizing healthcare.

A waste of (as yet un-procured) moneys?

Despite this optimism, critics are challenging the project on multiple fronts, from its financial feasibility to its strategic direction.

Elon Musk, head of the Department of Government Efficiency (DOGE) under President Donald Trump’s second administration and an OpenAI cofounder, cast doubt on the project’s funding.

Musk, who has since launched his own AI company, xAI, and its Grok language model family, posted on his social network, X, “They don’t actually have the money,” alleging that SoftBank — Stargate’s primary financial backer — has secured “well under $10B.”

In response, Altman replied this morning: “[I] genuinely respect your accomplishments and think you are the most inspiring entrepreneur of our time,” later writing that Musk was “wrong, as you surely know. want to come visit the first site already under way? this is great for the country. i realize what is great for the country isn’t always what’s optimal for your companies, but in your new role i hope you’ll mostly put [US flag emoji] first.”

Others have questioned the timing and strategic rationale behind the initiative. Tech entrepreneur and commentator Arnaud Bertrand took to X to contrast OpenAI’s infrastructure-heavy approach with the leaner, more decentralized strategy employed by China’s High-Flyer Capital Management, creators of the new, highest performing open-source large language model (LLM), DeepSeek-R1, released earlier this week.

Bertrand noted that DeepSeek has achieved performance parity with OpenAI’s latest models at just 3% of the cost, using far smaller GPU clusters and data centers.

He described the divergence as a collision of philosophies, with OpenAI betting on massive centralized infrastructure while DeepSeek pursues democratized, cost-efficient AI development.

“A fundamental question remains,” Bertrand wrote on X. “What will OpenAI customers be paying for exactly if much cheaper DeepSeek matches their latest models’ performance? Having spent an indecent amount of money on data centers isn’t a customer benefit in and of itself.”

Bertrand further argued that OpenAI’s focus on infrastructure may represent outdated thinking. “This $500B bet on infrastructure may be OpenAI fighting the last war,” he warned, pointing to DeepSeek’s success as evidence that innovation and agility — not scale — are the key drivers of modern AI progress.

The big philosophical divide: Will centralized or decentralized AI win out in the end?

At its core, the Stargate debate reflects a deeper philosophical divide about the future of AI. Proponents of the project argue that massive centralized infrastructure is essential to unlock artificial general intelligence (AGI) and tackle the world’s most pressing challenges. They view Stargate as a strategic imperative for maintaining U.S. global leadership in technology, especially in the face of rising competition from China.

Critics, however, question whether such centralization is necessary — or even viable — in an era when decentralized and open-source approaches are yielding increasingly competitive results. Bertrand, for example, compared the current AI race to the rivalry between Apple and Microsoft in the 1980s and 1990s.

Apple’s vertically integrated, premium ecosystem ultimately lost market dominance to Microsoft’s commoditized and widely accessible operating systems. He suggested that OpenAI’s customers may similarly gravitate toward more affordable alternatives like DeepSeek if the performance gap continues to narrow.

The debate over the Stargate Project extends beyond the tech industry, touching on national and global policy issues. Advocates see it as a necessary investment to ensure the U.S. retains its technological edge and addresses existential challenges like climate change, healthcare, and economic inequality. Skeptics worry it may divert resources from more effective and inclusive AI strategies, particularly as open-source models gain momentum.

The involvement of figures like Elon Musk, who occupies a unique position as both a government insider and a competitor to OpenAI through his xAI startup, adds further complexity to the discourse, as it challenges the project from within the same seat of power from which it was announced.

The Stargate Project is undeniably one of the most ambitious undertakings in the history of artificial intelligence, but its ultimate impact remains uncertain. If successful, it could reindustrialize the U.S. economy, secure American dominance in AI, and drive transformative breakthroughs across multiple industries. If its critics are correct, however, it could be remembered as a costly misstep — an investment that failed to anticipate the rise of leaner, more decentralized AI models.

As construction begins in Texas, the philosophical and strategic divide between centralized and decentralized approaches to AI has never been more pronounced. The stakes are enormous, and the outcome of this debate could shape the trajectory of artificial intelligence — and global power — for decades to come. For now, the world watches as America’s most ambitious AI initiative takes its first steps, while challengers like China’s DeepSeek continue to quietly rewrite the rules of the game.","**Is This the Next Moonshot? The $500 Billion Bet on AI That Could Change Everything**

**Why Read This?**

Hold on to your hats! A massive project called ""Stargate"" just launched, and it's about building super-powerful AI right here in the US. We're talking hundreds of billions of dollars and a plan to create AI smarter than humans. Is it genius or a crazy gamble?

**Why It Matters for You:**

Imagine a world where AI can solve huge problems, like curing diseases and stopping pandemics. That's the vision behind Stargate. It's like the government and big tech companies are teaming up to build the ultimate AI, which they hope will give America a big tech advantage. But here's the twist: some experts think this is a waste of money. They argue that smaller, cheaper AI is already catching up. So, is this going to be a historic leap forward, or just a very expensive mistake? The debate is heating up, and it’s crucial for everyone to pay attention because the future of AI could be shaped by this project.

**Want More?**

Explore the full details here: https://venturebeat.com/ai/openai-stargate-is-a-500b-bet-americas-ai-manhattan-project-or-costly-dead-end/
","9
"
Gaming comedy Mythic Quest Season 4 debuts on January 29 on Apple TV+,https://venturebeat.com/games/gaming-comedy-mythic-quest-season-4-debuts-on-january-29-on-apple-tv/,2025-01-24 23:16:00+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

Season 4 of a TV show is not something I write about very often, given my focus is video games. But Season 4 of Mythic Quest is another matter.

Debuting with the first two episodes on January 29 on Apple TV+, the show brings back the workplace comedy about a video game studio. The ensemble cast returns with stars including Rob McElhenney (as the mercurial creative director Ian Grimm) and Charlotte Nicdao (tech leader Poppy Li) and more. The show is good at skewering the sometimes ridiculous culture of video game industry, and it’s on the mark as it was originally created by Ubisoft.

The show is silly as usual, but I like how one of the opening scenes is about Play Pen, a user-generated content gimmick aimed at reviving the studio’s core online game. By the second episode, the users are all busy making sex games and the studio has to figure out what to do about it. David enlists the help of the studio’s ethics committee to find the answer. And, of course, AI is the next big trend that gets skewered in the show.

Game tester Rachel (played by Ashly Burch) has now been appointed the head of monetization for the studio. She will be hard-pressed to be more evil than Brad Bakshi (played by Dani Pudi) at making money.

The studio’s boss David Brittlesbee (played by David Hornsby, executive producer) continues to be caught in between the studio leads and the corporate headquarters. It’s still all-too-real when it comes to references to silly things in the game industry. Under preview, I’ve been checking it out.

The opening show, Boundaries, spells out the new responsibilities and boundary lines being drawn by the characters as their lives change. Ian and Poppy have rejoined the studio after striking out on their own. But Poppy, ever the programming workaholic, now isn’t working as hard because she has a new boyfriend. It’s interesting in that the show recognizes real-world game development problems, like too much crunch, or long work hours, often unpaid. So, of course, Poppy creates an AI version of herself to do work for her and help Ian with his middle-of-the-night strokes of brilliance.

The season will have 10 episodes, with the final one dropping on Apple TV+ on March 26.

Mythic Quest is executive produced by McElhenney and Charlie Day under their RCG banner, Michael Rotenberg and Nicholas Frenkel on behalf of 3Arts, and Margaret Boykin, Austin Dill, and Gérard Guillemot for Ubisoft Film & Television. Hornsby and Megan Ganz also executive produce. The series is produced for Apple TV+ by Lionsgate, 3 Arts Entertainment and Ubisoft. The first three seasons of Mythic Quest are now streaming globally on Apple TV+.

In the new season, the show also has an expansion of the Mythic Quest universe, Side Quest, which explores the lives of employees, players and fans who are impacted by the game in an anthology format. If you need a rest from CNN/Fox News all the time and our current political landscape, I recommend Mythic Quest as a nice diversion.","**Gamers and Non-Gamers: You Need to Watch This Hilarious Show**

**Why Read This?**

Forget serious news for a bit! ""Mythic Quest,"" a comedy about a video game studio, is back for Season 4 on Apple TV+. It's not just for gamers; it's a funny take on workplace craziness, and this season they're tackling the wild world of AI.

**Why It Matters for You:**

Imagine a workplace where everything is just a little bit ridiculous, from user-created sex games to an AI version of yourself. ""Mythic Quest"" nails it with its over-the-top characters and satire of tech culture. This season, they're skewering AI by having one of the main characters create an AI to do her work for her. If you've ever felt overwhelmed by tech, or just need a good laugh, this show is for you. It's a smart comedy that's both silly and surprisingly insightful.

**Want More?**

Explore the full details here: https://venturebeat.com/games/gaming-comedy-mythic-quest-season-4-debuts-on-january-29-on-apple-tv/
","7
"
Tech leaders respond to the rapid rise of DeepSeek,https://venturebeat.com/ai/tech-leaders-respond-to-the-rapid-rise-of-deepseek/,2025-01-24 21:10:39+00:00,"Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. Learn More

If you hadn’t heard, there’s a new AI star in town: DeepSeek, the subsidiary of Hong Kong-based quantitative analysis (quant) firm High-Flyer Capital Management, has sent shockwaves throughout Silicon Valley and the wider world with its release earlier this week of a new open source large reasoning model, DeepSeek R1, which matches OpenAI’s most powerful available model o1 — and at a fraction of the cost to users and to the company itself (when training it).

While the advent of DeepSeek R1 has already reshuffled a consistently topsy turvy, fast moving, intensely competitive market for new AI models — previous months saw OpenAI jockeying with Anthropic and Google for the most powerful proprietary models available, while Meta Platforms often came in with “close enough” open source rivals — the difference this time is the company behind the hot model is based in China, the geopolitical “frenemy” of the U.S., and whose tech sector was widely viewed, until this moment, as inferior to that of Silicon Valley.

As such, it’s caused no shortage of hand-wringing and existentialism from U.S. and western bloc techies, who are suddenly doubting OpenAI and the general big tech strategy of throwing more money and more compute (graphics processing units, GPUs, the powerful gaming chips typically used to train AI models) toward the problem of inventing ever more powerful models.

Yet some Western tech leaders have had a largely positive public response to DeepSeek’s rapid ascent.

Marc Andreessen, a co-inventor of the pioneering Mosaic web browser, co-founder of the Netscape browser company and current general partner at the famed Andreessen Horowitz (a16z) venture capital firm, posted on X today: “Deepseek R1 is one of the most amazing and impressive breakthroughs I’ve ever seen — and as open source, a profound gift to the world [robot emoji, salute emoji].”

Yann LeCun, the Chief AI Scientist for Meta’s Fundamental AI Research (FAIR) division, posted on his LinkedIn account:

“To people who see the performance of DeepSeek and think:

‘China is surpassing the US in AI.’

You are reading this wrong.

The correct reading is:

‘Open source models are surpassing proprietary ones.’



DeepSeek has profited from open research and open source (e.g. PyTorch and Llama from Meta)

They came up with new ideas and built them on top of other people’s work.

Because their work is published and open source, everyone can profit from it.

That is the power of open research and open source.”

And even Mark “Zuck” Zuckerberg, Meta AI’s founder and CEO, seemed to seek to counter the rise of DeepSeek with his own post on Facebook promising that a new version of Facebook’s open source AI model family Llama would be “the leading state of the art model” when it is released sometime this year. As he put it:

“This will be a defining year for AI. In 2025, I expect Meta AI will be the leading assistant serving more than 1 billion people, Llama 4 will become the leading state of the art model, and we’ll build an AI engineer that will start contributing increasing amounts of code to our R&D efforts. To power this, Meta is building a 2GW+ datacenter that is so large it would cover a significant part of Manhattan. We’ll bring online ~1GW of compute in ’25 and we’ll end the year with more than 1.3 million GPUs. We’re planning to invest $60-65B in capex this year while also growing our AI teams significantly, and we have the capital to continue investing in the years ahead. This is a massive effort, and over the coming years it will drive our core products and business, unlock historic innovation, and extend American technology leadership. Let’s go build!“

He even shared a graphic showing the 2 gigawatt datacenter mentioned in his post overlaid on Manhattan:

Clearly, even as he espouses a commitment to open source AI, Zuck is not convinced that DeepSeek’s approach of optimizing for efficiency while leveraging far fewer GPUs than major labs is the right one for Meta, or for the future of AI.

But with U.S. companies raising and/or spending record sums on new AI infrastructure that many experts have noted depreciate rapidly (due to hardware/chip and software advancements), the question remains which vision of the future will win out in the end to become the dominant AI provider for the world. Or maybe it will always be a multiplicity of models each with a smaller market share? Stay tuned, because this competition is getting closer and fiercer than ever.","**Is the AI Race About to Get a Whole Lot More Interesting?**

**Why Read This?**

There's a new AI challenger in town, and it's turning the tech world upside down. A company called DeepSeek just released an AI that's as powerful as the best out there, but it's much cheaper and open for anyone to use. Get ready for a shake-up in the world of AI!

**Why It Matters for You:**

Imagine a world where the most powerful AI isn't locked away by big companies, but available to everyone. That's what DeepSeek is trying to achieve. They've created a powerful AI that doesn't cost a fortune to train or use, and some experts think it might just change how AI is developed and accessed. The rise of DeepSeek is making tech leaders rethink their strategies, and it's raising some big questions: Do we need huge data centers and endless resources to build great AI, or can innovation come from smaller, more efficient models? The answer could impact the future of AI and who gets to benefit from it.

**Want More?**

Explore the full details here: https://venturebeat.com/ai/tech-leaders-respond-to-the-rapid-rise-of-deepseek/
","8
"
How a top Chinese AI model overcame US sanctions,https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/,2025-01-24 00:00:00,"“This could be a truly equalizing breakthrough that is great for researchers and developers with limited resources, especially those from the Global South,” says Hancheng Cao, an assistant professor in information systems at Emory University.

DeepSeek’s success is even more remarkable given the constraints facing Chinese AI companies in the form of increasing US export controls on cutting-edge chips. But early evidence shows that these measures are not working as intended. Rather than weakening China’s AI capabilities, the sanctions appear to be driving startups like DeepSeek to innovate in ways that prioritize efficiency, resource-pooling, and collaboration.

To create R1, DeepSeek had to rework its training process to reduce the strain on its GPUs, a variety released by Nvidia for the Chinese market that have their performance capped at half the speed of its top products, according to Zihan Wang, a former DeepSeek employee and current PhD student in computer science at Northwestern University.

DeepSeek R1 has been praised by researchers for its ability to tackle complex reasoning tasks, particularly in mathematics and coding. The model employs a “chain of thought” approach similar to that used by ChatGPT o1, which lets it solve problems by processing queries step by step.

Dimitris Papailiopoulos, principal researcher at Microsoft’s AI Frontiers research lab, says what surprised him the most about R1 is its engineering simplicity. “DeepSeek aimed for accurate answers rather than detailing every logical step, significantly reducing computing time while maintaining a high level of effectiveness,” he says.","**China's AI Secret Weapon: Outsmarting Sanctions with Smarter Tech**

**Why Read This?**

Think sanctions stop innovation? Think again! A Chinese company called DeepSeek just released a super-smart AI that's beating the odds. They did it by being clever, not just by throwing money at the problem, and it’s making people rethink how AI is developed.

**Why It Matters for You:**

Imagine trying to build something amazing with limited resources. That's the challenge DeepSeek faced, and they nailed it. They created a powerful AI that can tackle complex problems, even with less powerful tech. This isn’t just about tech rivalry; it shows that innovation can come from anywhere, not just Silicon Valley. It's a story about how constraints can actually lead to smarter solutions, and how even with limitations, it's possible to create groundbreaking tech. This could mean a more diverse and accessible AI future for everyone.

**Want More?**

Explore the full details here: https://www.technologyreview.com/2025/01/24/1110526/china-deepseek-top-ai-despite-sanctions/
","8
"
The US withdrawal from the WHO will hurt us all,https://www.technologyreview.com/2025/01/24/1110480/us-withdrawal-from-who-will-hurt-us-all/,2025-01-24 00:00:00,"The US is the biggest donor to the WHO, and the loss of this income is likely to have a significant impact on the organization, which develops international health guidelines, investigates disease outbreaks, and acts as an information-sharing hub for member states.

But the US will also lose out. “It’s a very tragic and sad event that could only hurt the United States in the long run,” says William Moss, an epidemiologist at Johns Hopkins Bloomberg School of Public Health in Baltimore.

Trump appears to take issue with the amount the US donates to the WHO. He points out that it makes a much bigger contribution than China, a country with a population four times that of the US. “It seems a little unfair to me,” he said as he prepared to sign the executive order.

It is true that the US is far and away the biggest financial supporter of the WHO. The US contributed $1.28 billion over the two-year period covering 2022 and 2023. By comparison, the second-largest donor, Germany, contributed $856 million in the same period. The US currently contributes 14.5% of the WHO’s total budget.

But it’s not as though the WHO sends a billion-dollar bill to the US. All member states are required to pay membership dues, which are calculated as a percentage of a country’s gross domestic product. For the US, this figure comes to $130 million. China pays $87.6 million. But the vast majority of the US’s contributions to the WHO are made on a voluntary basis—in recent years, the donations have been part of multibillion-dollar spending on global health by the US government. (Separately, the Bill and Melinda Gates Foundation contributed $830 million over 2022 and 2023.)

There’s a possibility that other member nations will increase their donations to help cover the shortfall left by the US’s withdrawal. But it is not clear who will step up—or what implications it will have to change the structure of donations.","**US Pulls Out of Global Health Org: Why It Matters to You**

**Why Read This?**

The US is cutting ties with the World Health Organization (WHO), a group that helps keep us safe from disease outbreaks. This move is a big deal, and it's not just about politics. It could actually affect your health.

**Why It Matters for You:**

Imagine if there was no organization tracking and sharing information about new diseases or health risks around the world. That's what the WHO does. The US was a major funder, and now that they’re pulling out, it could have some serious consequences. This isn’t just about the US; it's about all of us. The WHO sets health guidelines, investigates outbreaks, and helps keep everyone informed. Without US support, the WHO might struggle to do its job as effectively. This means we could all be at a greater risk of health issues. It's a reminder that global health is connected, and what happens in one country can impact everyone.

**Want More?**

Explore the full details here: https://www.technologyreview.com/2025/01/24/1110480/us-withdrawal-from-who-will-hurt-us-all/
","7
"
Why the next energy race is for underground hydrogen,https://www.technologyreview.com/2025/01/23/1110435/geologic-hydrogen/,2025-01-23 00:00:00,"I’ve been thinking about underground resources a lot this week, since I’ve been reporting a story about a new startup, Addis Energy. The company is looking to use subsurface rocks, and the conditions down there, to produce another useful chemical: ammonia. In an age of lab-produced breakthroughs, it feels like something of a regression to go digging for resources, but looking underground could help meet energy demand while also addressing climate change.

It’s rare that hydrogen turns up in oil and gas operations, and for decades, the conventional wisdom has been that there aren’t large deposits of the gas underground. Hydrogen molecules are tiny, after all, so even if the gas was forming there, the assumption was that it would just leak out.

However, there have been somewhat accidental discoveries of hydrogen over the decades, in abandoned mines or new well sites. There are reports of wells that spewed colorless gas, or flames that burned gold. And as people have looked more intentionally for hydrogen, they’ve started to find it.

As it turns out, hydrogen tends to build up in very different rocks from those that host oil and gas deposits. While fossil-fuel prospecting tends to focus on softer rocks, like organic-rich shale, hydrogen seems most plentiful in iron-rich rocks like olivine. The gas forms when chemical reactions at elevated temperature and pressure underground pull water apart. (There’s also likely another mechanism that forms hydrogen underground, called radiolysis, where radioactive elements emit radiation that can split water.)

Some research has put the potential amount of hydrogen available at around a trillion tons—plenty to feed our demand for centuries, even if we ramp up use of the gas.

The past few years have seen companies spring up around the world to try to locate and tap these resources. There’s an influx in Australia, especially the southern part of the country, which seems to have conditions that are good for making hydrogen. One startup, Koloma, has raised over $350 million to aid its geologic hydrogen exploration.

There are so many open questions for this industry, including how much hydrogen is actually going to be accessible and economical to extract. It’s not even clear how best to look for the gas today; researchers and companies are borrowing techniques and tools from the oil and gas industry, but there could be better ways.

It’s also unknown how this could affect climate change. Hydrogen itself may not warm the planet, but it can contribute indirectly to global warming by extending the lifetime of other greenhouse gases. It’s also often found with methane, a super-powerful greenhouse gas that could do major harm if it leaks out of operations at a significant level.","**Hidden Below Our Feet: A New Energy Source That Could Change Everything**

**Why Read This?**

Forget solar panels for a minute! Scientists are exploring a hidden resource deep underground: hydrogen. Turns out, there could be a lot of it, and it could be a game-changer for our energy needs. It's like finding a secret stash of clean fuel right under our noses!

**Why It Matters for You:**

Imagine a world powered by a clean, abundant fuel source that’s hiding beneath our feet. That’s what this hidden hydrogen could be. Researchers are discovering that this gas naturally forms deep inside the Earth, and it might be a solution to climate change. This is more than just a scientific discovery; it’s a story about how we can rethink our approach to energy. While there are still questions about how to get it safely, and how much is really down there, it's a promising path that’s worth watching closely.

**Want More?**

Explore the full details here: https://www.technologyreview.com/2025/01/23/1110435/geologic-hydrogen/
","8
"
OpenAI has upped its lobbying efforts nearly sevenfold,https://www.technologyreview.com/2025/01/21/1110260/openai-ups-its-lobbying-efforts-nearly-seven-fold/,2025-01-21 00:00:00,"OpenAI did not respond to questions about its lobbying efforts.

But perhaps more important, the disclosure is a clear signal of the company’s arrival as a political player, as its first year of serious lobbying ends and Republican control of Washington begins. While OpenAI’s lobbying spending is still dwarfed by its peers’—Meta tops the list of Big Tech spenders, with more than $24 million in 2024—the uptick comes as it and other AI companies have helped redraw the shape of AI policy.

For the past few years, AI policy has been something like a whack-a-mole response to the risks posed by deepfakes and misinformation. But over the last year, AI companies have started to position the success of the technology as pivotal to national security and American competitiveness, arguing that the government must therefore support the industry’s growth. As a result, OpenAI and others now seem poised to gain access to cheaper energy, lucrative national security contracts, and a more lax regulatory environment that’s unconcerned with the minutiae of AI safety.

While the big players seem more or less aligned on this grand narrative, messy divides on other issues are still threatening to break through the harmony on display at President Trump’s inauguration this week.

AI regulation really began in earnest after ChatGPT launched in November 2022. At that point, “a lot of the conversation was about responsibility,” says Liana Keesing, campaigns manager for technology reform at Issue One, a democracy nonprofit that tracks Big Tech’s influence.

Companies were asked what they’d do about sexually abusive deepfake images and election disinformation. “Sam Altman did a very good job coming in and painting himself early as a supporter of that process,” Keesing says.

OpenAI started its official lobbying effort around October 2023, hiring Chan Park—a onetime Senate Judiciary Committee counsel and Microsoft lobbyist—to lead the effort. Lawmakers, particularly then Senate majority leader Chuck Schumer, were vocal about wanting to curb these particular harms; OpenAI hired Schumer’s former legal counsel, Reginald Babin, as a lobbyist, according to data from OpenSecrets. This past summer, the company hired the veteran political operative Chris Lehane as its head of global policy.

OpenAI’s previous disclosures confirm that the company’s lobbyists subsequently focused much of last year on legislation like the No Fakes Act and the Protect Elections from Deceptive AI Act. The bills did not materialize into law. But as the year went on, the regulatory goals of AI companies began to change. “One of the biggest shifts that we’ve seen,” Keesing says, “is that they’ve really started to focus on energy.”","**ChatGPT's Creators Go to Washington: What You Should Know**

**Why Read This?**

The people behind ChatGPT, OpenAI, are getting serious about politics. They've ramped up their lobbying efforts in Washington, and it's not just about AI safety anymore. This could mean big changes in how AI is regulated and used.

**Why It Matters for You:**

Imagine if the companies making AI were also the ones setting the rules. That's kind of what's happening here. OpenAI is now trying to get the government on their side, pushing for things like cheaper energy and less regulation. This shift could impact everything from how AI is used in national security to how much power tech companies wield. It’s not just about deepfakes and misinformation anymore; it’s about shaping the future of AI and the world we live in. It’s a good idea to be aware of how these powerful players are trying to influence policy.

**Want More?**

Explore the full details here: https://www.technologyreview.com/2025/01/21/1110260/openai-ups-its-lobbying-efforts-nearly-seven-fold/
","7
"
What’s next for robots,https://www.technologyreview.com/2025/01/23/1110496/whats-next-for-robots/,2025-01-23 00:00:00,"“But those are expensive to create and time consuming, so you can only do a limited number of them,” says Rev Lebaredian, vice president of simulation technologies at Nvidia. Cosmos can instead take a handful of those examples and create a three-dimensional simulation of a hospital. It will then start making changes—different floor colors, different sizes of hospital beds—and create slightly different environments. “You’ll multiply that data that you captured in the real world millions of times,” Lebaredian says. In the process, the model will be fine-tuned to work well in that specific hospital setting.

It’s sort of like learning both from your experiences in the real world and from your own imagination (stipulating that your imagination is still bound by the rules of physics).

Teaching robots through AI and simulations isn’t new, but it’s going to become much cheaper and more powerful in the years to come.

A smarter brain gets a smarter body

Plenty of progress in robotics has to do with improving the way a robot senses and plans what to do—its “brain,” in other words. Those advancements can often happen faster than those that improve a robot’s “body,” which determine how well a robot can move through the physical world, especially in environments that are more chaotic and unpredictable than controlled assembly lines.

The military has always been keen on changing that and expanding the boundaries of what’s physically possible. The US Navy has been testing machines from a company called Gecko Robotics that can navigate up vertical walls (using magnets) to do things like infrastructure inspections, checking for cracks, flaws, and bad welding on aircraft carriers.

There are also investments being made for the battlefield. While nimble and affordable drones have reshaped rural battlefields in Ukraine, new efforts are underway to bring those drone capabilities indoors. The defense manufacturer Xtend received an $8.8 million contract from the Pentagon in December 2024 for its drones, which can navigate in confined indoor spaces and urban environments. These so-called “loitering munitions” are one-way attack drones carrying explosives that detonate on impact.

“These systems are designed to overcome challenges like confined spaces, unpredictable layouts, and GPS-denied zones,” says Rubi Liani, cofounder and CTO at Xtend. Deliveries to the Pentagon should begin in the first few months of this year.

Another initiative—sparked in part by the Replicator project, the Pentagon’s plan to spend more than $1 billion on small unmanned vehicles—aims to develop more autonomously controlled submarines and surface vehicles. This is particularly of interest as the Department of Defense focuses increasingly on the possibility of a future conflict in the Pacific between China and Taiwan. In such a conflict, the drones that have dominated the war in Ukraine would serve little use because battles would be waged almost entirely at sea, where small aerial drones would be limited by their range. Instead, undersea drones would play a larger role.","**Robots Are Getting Smarter AND Stronger: What's Coming Next**

**Why Read This?**

Robots are evolving fast, and it's not just about those clunky robots you see in movies. They're becoming incredibly smart and capable thanks to AI, and they're about to change how we do things, from healthcare to the battlefield.

**Why It Matters for You:**

Imagine robots that can learn in a virtual world and then apply those skills in real life. That's what's happening now. AI is helping robots figure out how to move, plan, and adapt to different environments. This is opening up a world of possibilities: robots that can inspect buildings, navigate underwater, or work in dangerous situations. The military is also getting in on the action, developing drones that can operate in tricky urban settings. This shows that robots are becoming much more than just factory workers; they're evolving into dynamic helpers in almost every aspect of our lives.

**Want More?**

Explore the full details here: https://www.technologyreview.com/2025/01/23/1110496/whats-next-for-robots/
","8
"
Anthropic plans to release a ‘two-way’ voice mode for Claude,https://techcrunch.com/2025/01/21/anthropic-plans-to-release-a-two-way-voice-mode-for-claude/,2025-01-21 00:00:00,"In Brief

Anthropic CEO Dario Amodei says that the company plans to release a “two-way” voice mode for its chatbot, Claude, as well as a memory feature that lets Claude remember more about users and past conversations.

Speaking to The Wall Street Journal at the World Economic Forum at Davos, Amodei also revealed that Anthropic expects to release “smarter” AI models in the coming months, and that the company has been “overwhelmed” by the “surge in demand” in the last year.

“The surge in demand we’ve seen over the last year, and particularly in the last three months, has overwhelmed our ability to provide the needed compute,” Amodei said.

Anthropic is racing to keep pace with its chief AI rival, OpenAI, in an extremely capital-intensive sector. Despite having raised $13.7 billion in capital to date, Anthropic reportedly lost billions of dollars last year. Anthropic is said to be in talks to raise another ~$2 billion at a $60 billion valuation.","**Get Ready to Talk to Your AI: Claude is Getting a Voice**

**Why Read This?**

The AI chatbot Claude is about to get a lot more human-like! The company behind it, Anthropic, is planning to add a voice feature that lets you have a two-way conversation with it. It'll also remember past chats, making the whole experience feel much more natural.

**Why It Matters for You:**

Imagine talking to an AI just like you would a friend, and it remembers everything you've talked about before. That's what's coming with Claude. This upgrade will make AI interactions less like typing to a computer and more like having a real conversation. This is more than just a cool new feature; it’s about making AI more accessible and useful for everyone. It also shows how fast the field of AI is changing, with companies racing to make the technology more powerful and human-friendly.

**Want More?**

Explore the full details here: https://techcrunch.com/2025/01/21/anthropic-plans-to-release-a-two-way-voice-mode-for-claude/
","7
"
Trump signs exec order delaying TikTok enforcement action for 75 days,https://techcrunch.com/2025/01/20/trump-signs-exec-order-delaying-tiktok-enforcement-action-for-75-days/,2025-01-20 00:00:00,"In Brief

President Donald Trump has signed an executive order aimed at restoring TikTok service in the U.S.

The order instructs relevant government agencies to “pursue a resolution” that “protects national security” while “saving [TikTok.]” Via the order, Trump is instructing the U.S. attorney general not to take any action for 75 days to enforce the Protecting Americans from Foreign Adversary Controlled Applications Act (PAFACA), the act that effectively banned TikTok in the U.S. on Sunday, January 19.

“During this period, the Department of Justice shall take no action to enforce the Act or impose any penalties against any entity for any noncompliance with the Act,” the executive order reads. “Even after the expiration of the above-specified period, the Department of Justice shall not take any action to enforce the Act […]”

Trump’s move comes on the heels of a U.S. Supreme Court decision to uphold the PAFACA, which passed with bipartisan congressional support during former President Joe Biden’s term.","**TikTok's Back on the Table? Trump's Move That Could Change Everything**

**Why Read This?**

Remember when TikTok was supposed to be banned? Well, President Trump just hit pause on that! He's signed an order that could bring TikTok back to the US, but there are some big questions about what it all means.

**Why It Matters for You:**

Imagine not being able to use your favorite social media app. That’s what almost happened with TikTok. Now, Trump is saying the government has to find a way to keep TikTok running while also protecting national security. This decision is more than just about social media; it’s about how much control the government has over the apps we use. This could set a precedent for future tech regulations, and it might make you wonder about how our online lives are being managed.

**Want More?**

Explore the full details here: https://techcrunch.com/2025/01/20/trump-signs-exec-order-delaying-tiktok-enforcement-action-for-75-days/
","7
"
Mistral AI plans IPO,https://techcrunch.com/2025/01/21/mistral-ai-plans-ipo/,2025-01-21 00:00:00,"In Brief

French AI lab Mistral is working toward an initial public offering, co-founder and CEO Arthur Mensch said Tuesday in an interview with Bloomberg at the World Economic Forum in Davos.

Mistral is “not for sale,” Mensch said, adding that the company plans to open an office in Singapore to focus on the Asia-Pacific region and is growing in Europe and the U.S. “Of course, [an IPO is] the plan.”

Mistral, which Mensch launched in 2023 alongside former researchers from Google’s DeepMind and Meta, is often described as Europe’s answer to U.S. incumbents like OpenAI. The lab releases AI models and services that compete with offerings from OpenAI and others, including a ChatGPT-like platform called Le Chat.

Mistral has raised around $1.14 billion in capital to date from investors including Andreessen Horowitz, General Catalyst, and Lightspeed Venture Partners. The company was reportedly last valued at around $6 billion.","**Europe's AI Star Is Going Public: What It Means for You**

**Why Read This?**

A European AI company called Mistral is planning to go public, which is a big deal in the tech world. They're often called Europe's answer to OpenAI, the creators of ChatGPT, and this move could change the landscape of AI development.

**Why It Matters for You:**

Imagine if there was a real competitor to the big AI companies we know. That's what Mistral is trying to be. They're creating AI models that are giving OpenAI a run for their money, and now they're opening up to public investment. This isn't just about the stock market; it's about competition and innovation. This could lead to better AI tools and services for everyone. It also shows that the future of AI is not just in Silicon Valley; it's a global race, and this development will be an important piece of the puzzle.

**Want More?**

Explore the full details here: https://techcrunch.com/2025/01/21/mistral-ai-plans-ipo/
","7
"
President Trump repeals Biden’s AI executive order,https://techcrunch.com/2025/01/20/president-trump-repeals-bidens-ai-executive-order/,2025-01-20 00:00:00,"In Brief

During his first day in office, President Donald Trump revoked a 2023 executive order signed by former President Joe Biden that sought to reduce the potential risks AI poses to consumers, workers, and national security.

Biden’s executive order directed the Commerce Department’s National Institute of Standards and Technology (NIST) to author guidance that helps companies identify — and correct for — flaws in models, including biases. The executive order also required developers of AI systems to share the results of safety tests with the U.S. government before they were released to the public.

Critics allied with Trump argued that the executive order’s reporting requirements were onerous and effectively forced companies to disclose their trade secrets. During his campaign, Trump promised policies that would “support AI development rooted in free speech and human flourishing” — but declined to go into detail.","**Trump Just Changed the Rules on AI: What You Need to Know**

**Why Read This?**

President Trump just made a big move on AI, throwing out an order from the previous administration that was trying to keep AI safe and fair. This could lead to some big changes about how AI is developed and used in the US.

**Why It Matters for You:**

Imagine a world where AI is used in ways that are biased, unfair, or even dangerous. The previous rules were meant to help avoid that, but Trump's move could mean less oversight and fewer safety checks. It’s about balancing innovation with responsibility. This could change how companies are allowed to develop and release AI tech, and ultimately, how safe and fair these powerful tools are for everyone. It's worth paying attention because these decisions could affect our future.

**Want More?**

Explore the full details here: https://techcrunch.com/2025/01/20/president-trump-repeals-bidens-ai-executive-order/
","7
"
OpenAI’s agent tool may be nearing release,https://techcrunch.com/2025/01/20/openais-agent-tool-may-be-nearing-release/,2025-01-20 00:00:00,"OpenAI may be close to releasing an AI tool that can take control of your PC and perform actions on your behalf.

Tibor Blaho, a software engineer with a reputation for accurately leaking upcoming AI products, claims to have uncovered evidence of OpenAI’s long-rumored Operator tool. Publications including Bloomberg have previously reported on Operator, which is said to be an “agentic” system capable of autonomously handling tasks like writing code and booking travel.

According to The Information, OpenAI is targeting January as Operator’s release month. Code uncovered by Blaho this weekend adds credence to that reporting.

OpenAI’s ChatGPT client for macOS has gained options, hidden for now, to define shortcuts to “Toggle Operator” and “Force Quit Operator,” per Blaho. And OpenAI has added references to Operator on its website, Blaho said — albeit references that aren’t yet publicly visible.

According to Blaho, OpenAI’s site also contains not-yet-public tables comparing the performance of Operator to other computer-using AI systems. The tables may well be placeholders. But if the numbers are accurate, they suggest that Operator isn’t 100% reliable, depending on the task.

On OSWorld, a benchmark that tries to mimic a real computer environment, “OpenAI Computer Use Agent (CUA)” — possibly the AI model powering Operator — scores 38.1%, ahead of Anthropic’s computer-controlling model but well short of the 72.4% humans score. OpenAI CUA surpasses human performance on WebVoyager, which evaluates an AI’s ability to navigate and interact with websites. But the model falls short of human-level scores on another web-based benchmark, WebArena, according to the leaked benchmarks.

Operator also struggles with tasks a human could perform easily, if the leak is to be believed. In a test that tasked Operator with signing up with a cloud provider and launching a virtual machine, Operator was only successful 60% of the time. Tasked with creating a Bitcoin wallet, Operator succeeded only 10% of the time.

We’ve reached out to OpenAI for comment and will update this piece if we hear back.

OpenAI’s imminent entry into the AI agent space comes as rivals, including the aforementioned Anthropic, Google, and others, make plays for the nascent segment. AI agents may be risky and speculative, but tech giants are already touting them as the next big thing in AI. According to analytics firm Markets and Markets, the market for AI agents could be worth $47.1 billion by 2030.

Agents today are rather primitive. But some experts have raised concerns about their safety, should the technology rapidly improve.

One of the leaked charts shows Operator performing well on selected safety evaluations, including tests that try to get the system to perform “illicit activities” and search for “sensitive personal data.” Reportedly, safety testing is among the reasons for Operator’s long development cycle. In a recent X post, OpenAI co-founder Wojciech Zaremba criticized Anthropic for releasing an agent he claims lacks safety mitigations.

“I can only imagine the negative reactions if OpenAI made a similar release,” Zaremba wrote.

It’s worth noting that OpenAI has been criticized by AI researchers, including ex-staff, for allegedly de-emphasizing safety work in favor of quickly productizing its technology.

TechCrunch has an AI-focused newsletter! Sign up here to get it in your inbox every Wednesday.","**Is Your Computer About to Get a Mind of Its Own? OpenAI's New Tool**

**Why Read This?**

Get ready for some serious tech news! OpenAI, the company behind ChatGPT, might be launching a tool called ""Operator"" that can actually take control of your computer and do things for you. Yes, really!

**Why It Matters for You:**

Imagine having an AI assistant that can book your flights, write code, or even sign up for services online - without you having to lift a finger. That's what Operator is designed to do. While it's not perfect yet, this tool is a glimpse into a future where AI is much more involved in our daily lives. It raises some big questions about what AI should do on its own and how we can ensure these tools are safe. This isn’t just about convenience; it's about the next level of AI and how much control we're comfortable giving it.

**Want More?**

Explore the full details here: https://techcrunch.com/2025/01/20/openais-agent-tool-may-be-nearing-release/
","8
"
